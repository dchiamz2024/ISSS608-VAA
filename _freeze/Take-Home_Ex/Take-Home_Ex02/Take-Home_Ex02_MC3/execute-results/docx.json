{
  "hash": "c5561897a9e4dfd89f227340b4d84c40",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Take-Home Assignment 2\"\ndescription: \"\"\nauthor: \"David Chiam\"\ndate: \"22 May 2025\"\ndate-modified: \"31 May 2025\"\nformat: docx\neditor: visual\nexecute: \n  eval: false\n  echo: true\n  warning: false\n  freeze: true\n---\n\n# **Take Home Assignment 2 on Mini-Challenge 3**\n\n## **1 - Getting Started**\n\n### 1.1 - Load the R packages for this assignment\n\nFor the purpose of this assignment, five R packages will be used. They are tidyverse, jsonlite, tidygraph, ggraph and SmartEDA.\n\nIn the code chunk below, p_load() of pacman package is used to load the R packages into R environment.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(tidyverse, jsonlite, \n               tidygraph, ggraph, SmartEDA, \n               ggrepel, scales, lubridate, dplyr, viridis)\n```\n:::\n\n\n### 1.2 - Importing Knowledge Graph Data\n\nFor the purpose of this exercise, *mc3.json* file will be used. Before getting started, you should have the data set in the **data** sub-folder.\n\nIn the code chunk below, `fromJSON()` of **jsonlite** package is used to import *mc3.json* file into R and save the output object\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMC3 <- fromJSON(\"data/MC3_graph.json\")\nMC3_schema <- fromJSON(\"data/MC3_schema.json\")\n```\n:::\n\n\n### 1.3 - **Data Overview**\n\nThe dataset was provided by VAST Challenge for MC3. This report utilizes two core datasets: MC3_graph.json, which encodes the knowledge graph of communications, events, and relationships; and MC3_schema.json, which defines the structure, subtypes, and attributes of each node and edge type within the graph. There ngraph contains a total of 1159 nodes and 3226 edges. Full description of node attributes and edge attributes is shown below.\n\n**Nodes Attributes** are as such:\n\n![Node Subtypes](Images/Node%20Attributes.png){fig-align=\"center\" width=\"600\"}\n\n**Edge Attributes** are as such:\n\n![Node-Edge-Node Matrix](Images/Edge%20Attributes.png){fig-align=\"center\" width=\"594\"}\n\n### 1.4 - **Inspecting knowledge graph structure**\n\nBefore preparing the data, it is always a good practice to examine the structure of *mc3* knowledge graph.\n\nIn the code chunk below `glimpse()` is used to reveal the structure of *mc3* knowledge graph.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(MC3)\n```\n:::\n\n\n::: callout-warning\nNotice that¬†*Industry*¬†field is in list data type. In general, this data type is not acceptable by¬†`tbl_graph()`¬†of¬†**tidygraph**. In order to avoid error arise when building tidygraph object, it is wiser to exclude this field from the edges data table. However, it might be still useful in subsequent analysis.\n:::\n\n### 1.5 - Extract the edges and nodes tables\n\nNext,¬†`as_tibble()`¬†of¬†**tibble**¬†package package is used to extract the nodes and links tibble data frames from¬†*mc3*¬†tibble dataframe into two separate tibble dataframes called¬†*mc3_nodes*¬†and¬†*mc3_edges*¬†respectively.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmc3_nodes <- as_tibble(MC3$nodes)\nmc3_edges <- as_tibble(MC3$edges)\n```\n:::\n\n\n### 1.6 - Brief Analyis of the extracted edges and nodes data (visuals)\n\nIt is time for us to apply appropriate EDA methods to examine the data.\n\n**Nodes:**\n\n:::: panel-tabset\nIn the code chunk below, `ExpCatViz()` of SmartEDA package is used to reveal the frequency distribution of all categorical fields in *mc3_nodes* tibble dataframe.\n\n### The Code Chunk\n\n\n::: {.cell}\n\n```{.r .cell-code}\nExpCatViz(data=mc3_nodes,\n          col=\"lightblue\")\n```\n:::\n\n\n### The Plots\n\n\n::: {.cell}\n\n```{.r .cell-code}\nExpCatViz(data=mc3_nodes,\n          col=\"lightblue\")\n```\n:::\n\n\n::: callout-note\nWhat useful discovery can you obtained from the visualisation above?\n:::\n::::\n\n**Edges:**\n\n:::: panel-tabset\nOn the other hands, code chunk below uses¬†`ExpCATViz()`¬†of SmartEDA package to reveal the frequency distribution of all categorical fields in¬†*mc3_edges*¬†tibble dataframe.\n\n### The Code Chunk\n\n\n::: {.cell}\n\n```{.r .cell-code}\nExpCatViz(data=mc3_edges,\n          col=\"lightblue\")\n```\n:::\n\n\n### The Plots\n\n\n::: {.cell}\n\n:::\n\n\n::: callout-note\nWhat useful discovery can you obtained from the visualisation above?\n:::\n::::\n\n## 2 - **Data Cleaning and Wrangling**\n\n### **2.1 - Cleaning and wrangling nodes**\n\nCode chunk below performs the following data cleaning tasks:\n\n-   convert values in id field into character data type,\n-   exclude records with `id` value are na,\n-   exclude records with similar id values,\n-   exclude `thing_collected` field, and\n-   save the cleaned tibble dataframe into a new tibble datatable called `mc3_nodes_cleaned`.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmc3_nodes_cleaned <- mc3_nodes %>%\n  mutate(id = as.character(id)) %>%\n  filter(!is.na(id)) %>%\n  distinct(id, .keep_all = TRUE) %>%\n  select(-thing_collected)\n```\n:::\n\n\n### **2.2 - Cleaning and wrangling edges**\n\nNext, the code chunk below will be used to:\n\n-   rename source and target fields to from_id and to_id respectively,\n-   convert values in from_id and to_id fields to character data type,\n-   exclude values in from_id and to_id which not found in the id field of mc3_nodes_cleaned,\n-   exclude records whereby from_id and/or to_id values are missing, and\n-   save the cleaned tibble dataframe and called it mc3_edges_cleaned.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmc3_edges_cleaned <- mc3_edges %>%\n  rename(from_id = source, \n         to_id = target) %>%\n  mutate(across(c(from_id, to_id), \n                as.character)) %>%\n  filter(from_id %in% mc3_nodes_cleaned$id, \n         to_id %in% mc3_nodes_cleaned$id) %>%\n  filter(!is.na(from_id), !is.na(to_id))\n```\n:::\n\n\nNext, code chunk below will be used to create mapping of character id in¬†`mc3_nodes_cleaned`¬†to row index.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nnode_index_lookup <- mc3_nodes_cleaned %>%\n  mutate(.row_id = row_number()) %>%\n  select(id, .row_id)\n```\n:::\n\n\nNext, the code chunk below will be used to join and convert¬†`from_id`¬†and¬†`to_id`¬†to integer indices. At the same time we also drop rows with unmatched nodes.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmc3_edges_indexed <- mc3_edges_cleaned %>%\n  left_join(node_index_lookup, \n            by = c(\"from_id\" = \"id\")) %>%\n  rename(from = .row_id) %>%\n  left_join(node_index_lookup, \n            by = c(\"to_id\" = \"id\")) %>%\n  rename(to = .row_id) %>%\n  select(from, to, is_inferred, type) %>%\n  filter(!is.na(from) & !is.na(to))  \n```\n:::\n\n\nNext the code chunk below is used to subset nodes to only those referenced by edges.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nused_node_indices <- sort(\n  unique(c(mc3_edges_indexed$from, \n           mc3_edges_indexed$to)))\n\nmc3_nodes_final <- mc3_nodes_cleaned %>%\n  slice(used_node_indices) %>%\n  mutate(new_index = row_number())\n```\n:::\n\n\nWe will then use the code chunk below to rebuild lookup from old index to new index.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nold_to_new_index <- tibble(\n  old_index = used_node_indices,\n  new_index = seq_along(\n    used_node_indices))\n```\n:::\n\n\nLastly, the code chunk below will be used to update edge indices to match new node table.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmc3_edges_final <- mc3_edges_indexed %>%\n  left_join(old_to_new_index, \n            by = c(\"from\" = \"old_index\")) %>%\n  rename(from_new = new_index) %>%\n  left_join(old_to_new_index, \n            by = c(\"to\" = \"old_index\")) %>%\n  rename(to_new = new_index) %>%\n  select(from = from_new, to = to_new, \n         is_inferred, type)\n```\n:::\n\n\n### **2.3 - Building the tidygraph object**\n\nNow we are ready to build the tidygraph object by using the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmc3_graph <- tbl_graph(\n  nodes = mc3_nodes_final,\n  edges = mc3_edges_final,\n  directed = TRUE\n)\n```\n:::\n\n\nAfter the tidygraph object is created, it is always a good practice to examine the object by using¬†`str()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(mc3_graph)\n```\n:::\n\n\n## 3 - **Exploratory Data Analysis (after cleaning & wrangling)**\n\nSeveral of the¬†**ggraph**¬†layouts involve randomisation. In order to ensure reproducibility, it is necessary to set the seed value before plotting by using the code chunk below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1818)\n```\n:::\n\n\n### **3.1 - Visualising the knowledge graph**\n\nShows how many nodes are of type `Entity`, `Event`, or `Relationship`.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmc3_nodes_final %>%\n  count(type, sort = TRUE) %>%\n  ggplot(aes(x = reorder(type, -n), y = n, fill = type)) +\n  geom_col() +\n  geom_text(aes(label = n), vjust = -0.3) +\n  labs(title = \"Node Type Distribution\", x = \"Type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n```\n:::\n\n\nIn the code chunk below,¬†**ggraph**¬†functions are used to create the whole graph.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggraph(mc3_graph, \n       layout = \"fr\") +\n  geom_edge_link(alpha = 0.3, \n                 colour = \"gray\") +\n  geom_node_point(aes(color = `type`), \n                  size = 4) +\n  geom_node_text(aes(label = type), \n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()\n```\n:::\n\n\n### **3.2 - Entity Sub_type Distribution**\n\nFocuses on what kinds of actors are in the graph ‚Äî Person, Vessel, Organization, etc.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Define color mapping\nsubtype_colors <- c(\n  \"Person\" = \"#2ca5ff\",\n  \"Organization\" = \"#f5ee15\",\n  \"Vessel\" = \"#FB7E81\",\n  \"Group\" = \"#25e158\",\n  \"Location\" = \"#ec4bff\"\n)\n\nmc3_nodes_final %>%\n  filter(type == \"Entity\") %>%\n  count(sub_type, sort = TRUE) %>%\n  ggplot(aes(x = reorder(sub_type, n), y = n, fill = sub_type)) +\n  geom_col() +\n  coord_flip() +\n  geom_text(aes(label = n), hjust = -0.1) +\n  labs(title = \"Entity Sub-type Distribution\", x = \"Sub-type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n```\n:::\n\n\n### **3.3 - Event Sub_type Distribution**\n\nTo understand what kinds of actions dominate ‚Äî Communication, Monitoring, Assessment, etc.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmc3_nodes_final %>%\n  filter(type == \"Event\") %>%\n  count(sub_type, sort = TRUE) %>%\n  ggplot(aes(x = reorder(sub_type, n), y = n, fill = sub_type)) +\n  geom_col() +\n  coord_flip() +\n  geom_text(aes(label = n), hjust = -0.1) +\n  labs(title = \"Event Sub-type Distribution\", x = \"Sub-type\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n```\n:::\n\n\n### **3.4a - List of Communication Participants**\n\nThis finds all Entities that **sent or received** communication events ‚Äî i.e., actors who participated in messaging.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(DT)\n\n# Step 1: Get all Communication Event IDs\ncomm_event_ids <- mc3_nodes_cleaned %>%\n  filter(type == \"Event\", sub_type == \"Communication\") %>%\n  pull(id)\n\n# Step 2: Extract 'sent' edges for communication events\ncomm_sent_edges <- mc3_edges_cleaned %>%\n  filter(type == \"sent\", to_id %in% comm_event_ids) %>%\n  select(comm_id = to_id, sender_id = from_id)\n\n# Step 3: Extract 'received' edges for same communication events\ncomm_received_edges <- mc3_edges_cleaned %>%\n  filter(type == \"received\", from_id %in% comm_event_ids) %>%\n  select(comm_id = from_id, receiver_id = to_id)\n\n# Step 4: Join sent and received edges by communication ID\ncomm_pairs <- comm_sent_edges %>%\n  inner_join(comm_received_edges, by = \"comm_id\")\n\n# Step 5: Add sender and receiver labels\nparticipants_named <- comm_pairs %>%\n  left_join(mc3_nodes_cleaned %>% select(id, sender_label = label), by = c(\"sender_id\" = \"id\")) %>%\n  left_join(mc3_nodes_cleaned %>% select(id, receiver_label = label), by = c(\"receiver_id\" = \"id\"))\n\n\n\n# Step7: Interactive summary of top sender‚Äìreceiver pairs\nparticipants_named %>%\n  count(sender_label, receiver_label, sort = TRUE) %>%\n  datatable(\n    caption = \"Top Communication Pairs (Sender ‚Üí Receiver)\",\n    colnames = c(\"Sender\", \"Receiver\", \"Message Count\"),\n    options = list(pageLength = 10, autoWidth = TRUE),\n    rownames = FALSE\n  )\n```\n:::\n\n\n### **3.4b - Network Visual of Communication Participants**\n\nThis code creates an **interactive communication network graph** using `visNetwork`, where:\n\n-   Each **node** represents a person or entity, **node size** is based on total messages **sent** by that participant.\n-   Each **edge (arrow)** represents a communication sent from one participant to another, the thicker the edge, the more message sent to that particular receiver.\n\n**Ver 1: Layout_in_circle**\n\nMessage Senders are arranged from most to the least number of messages sent.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(visNetwork)\n\n# Step 1: Summarize communication edges\ncomm_edges_vis <- participants_named %>%\n  count(sender_id, receiver_id, sort = TRUE) %>%\n  rename(from = sender_id, to = receiver_id, value = n)\n\n# Step 2: Compute messages sent per node\nmessage_counts <- comm_edges_vis %>%\n  group_by(from) %>%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare nodes, merge with message count and add color/shape\nnodes_vis <- mc3_nodes_cleaned %>%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %>%\n  select(id, label, sub_type) %>%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %>%\n  mutate(\n    sent_count = replace_na(sent_count, 0),\n    size = rescale(sent_count, to = c(10, 40)),\n    title = paste0(label, \"<br>Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"<br>Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#2ca5ff\",\n      sub_type == \"Organization\" ~ \"#f5ee15\",\n      sub_type == \"Vessel\" ~ \"#FB7E81\",\n      sub_type == \"Group\" ~ \"#25e158\",\n      sub_type == \"Location\" ~ \"#ec4bff\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Organization\" ~ \"square\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      sub_type == \"Group\" ~ \"star\",\n      sub_type == \"Location\" ~ \"diamond\",\n      TRUE ~ \"dot\"\n    ),\n  ) %>%\n  arrange(desc(size))\n\n# Step 4: Format visNetwork edges\nedges_vis <- comm_edges_vis %>%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Define legend items\nlegend_nodes <- data.frame(\n  label = c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\"),\n  color = c(\"#2ca5ff\", \"#f5ee15\", \"#FB7E81\", \"#25e158\", \"#ec4bff\"),\n  shape = c(\"dot\", \"square\", \"triangle\", \"star\", \"diamond\"),\n  stringsAsFactors = FALSE\n)\n\n# Step 6: Render network with legend\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"1000px\") %>%\n  visNodes(\n    size = nodes_vis$size\n    # color and shape are picked up from nodes_vis columns automatically\n  ) %>%\n  visLegend(\n    addNodes = lapply(1:nrow(legend_nodes), function(i) {\n      list(\n        label = legend_nodes$label[i],\n        shape = legend_nodes$shape[i],\n        color = legend_nodes$color[i]\n      )\n    }),\n    useGroups = FALSE,\n    width = 0.15\n  ) %>%\n  visEdges(smooth = FALSE) %>%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %>%\n  visIgraphLayout(layout = \"layout_in_circle\") %>%\n  visPhysics(enabled = FALSE) %>%\n  visLayout(randomSeed = 1818)\n```\n:::\n\n\n**Ver 2: Layout_on_sphere**\n\nFrom this plot, it reveals that some pairs (e.g., Miranda Jordan and Clepper Jensen) mainly communicate with each other, suggesting isolated or private channels outside the broader network.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(visNetwork)\n\n# Step 1: Summarize communication edges\ncomm_edges_vis <- participants_named %>%\n  count(sender_id, receiver_id, sort = TRUE) %>%\n  rename(from = sender_id, to = receiver_id, value = n)\n\n# Step 2: Compute messages sent per person (by sender)\nmessage_counts <- comm_edges_vis %>%\n  group_by(from) %>%\n  summarise(sent_count = sum(value), .groups = \"drop\")\n\n# Step 3: Prepare nodes with label, subtype, color, shape, and scaled size\nnodes_vis <- mc3_nodes_cleaned %>%\n  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %>%\n  select(id, label, sub_type) %>%\n  left_join(message_counts, by = c(\"id\" = \"from\")) %>%\n  mutate(\n    size = if_else(\n      sub_type == \"Person\",\n      rescale(sent_count, to = c(10, 40), na.rm = TRUE),\n      15\n    ),\n    title = paste0(label, \"<br>Sub-type: \", sub_type,\n                   ifelse(!is.na(sent_count), paste0(\"<br>Sent: \", sent_count, \" messages\"), \"\")),\n    color = case_when(\n      sub_type == \"Person\" ~ \"#2ca5ff\",\n      sub_type == \"Organization\" ~ \"#f5ee15\",\n      sub_type == \"Vessel\" ~ \"#FB7E81\",\n      sub_type == \"Group\" ~ \"#25e158\",\n      sub_type == \"Location\" ~ \"#ec4bff\",\n      TRUE ~ \"black\"\n    ),\n    shape = case_when(\n      sub_type == \"Person\" ~ \"dot\",\n      sub_type == \"Organization\" ~ \"square\",\n      sub_type == \"Vessel\" ~ \"triangle\",\n      sub_type == \"Group\" ~ \"star\",\n      sub_type == \"Location\" ~ \"diamond\",\n      TRUE ~ \"dot\"\n    )\n  )\n\n# Step 4: Format edges\nedges_vis <- comm_edges_vis %>%\n  mutate(\n    arrows = \"to\",\n    width = rescale(value, to = c(1, 6)),\n    title = paste(\"Messages:\", value)\n  )\n\n# Step 5: Legend mapping\nlegend_nodes <- data.frame(\n  label = c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\"),\n  color = c(\"#2ca5ff\", \"#f5ee15\", \"#FB7E81\", \"#25e158\", \"#ec4bff\"),\n  shape = c(\"dot\", \"square\", \"triangle\", \"star\", \"diamond\"),\n  stringsAsFactors = FALSE\n)\n\n# Step 6: Render the network with layout_on_sphere and legend\nvisNetwork(nodes_vis, edges_vis, width = \"100%\", height = \"900px\") %>%\n  visNodes(\n    size = nodes_vis$size\n    # color and shape columns are automatically used\n  ) %>%\n  visLegend(\n    addNodes = lapply(1:nrow(legend_nodes), function(i) {\n      list(\n        label = legend_nodes$label[i],\n        shape = legend_nodes$shape[i],\n        color = legend_nodes$color[i]\n      )\n    }),\n    useGroups = FALSE,\n    width = 0.15\n  ) %>%\n  visEdges(smooth = FALSE) %>%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %>%\n  visIgraphLayout(layout = \"layout_on_sphere\") %>%\n  visPhysics(enabled = FALSE) %>%\n  visLayout(randomSeed = 1818)\n```\n:::\n\n\n## 4 - Task 1a & 1b: Daily Temporal Patterns in Communications over the Two Weeks üéØ\n\n::: callout-note\n## VAST Challenge Task & Question 1a and 1b\n\nClepper found that messages frequently came in at around the same time each day.\n\n-   Develop a graph-based visual analytics approach to identify any daily temporal patterns in communications.\n-   How do these patterns shift over the two weeks of observations?\n:::\n\n**Objective**\n\n1.  Identify **when** communications happen most often during each day.\n2.  Detect **shifts in these patterns** over the 2-week period.\n3.  Later: Focus on a **specific entity** (e.g., Nadia Conti) and explore **who influences them**.\n\n### Step 1: Extract & Parse Communication Event Timestamps\n\nExtract the Communication Timestamps from `mc3_nodes_final` and filter for communication events.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter for Communication events\ncomm_events <- mc3_nodes_final %>%\n  filter(type == \"Event\", sub_type == \"Communication\") %>%\n  mutate(timestamp = ymd_hms(timestamp)) %>%\n  filter(!is.na(timestamp)) %>%\n  mutate(\n    day = as.Date(timestamp),\n    hour = hour(timestamp)\n  )\n```\n:::\n\n\nParse the Communication Timestamp into the format \"dd/mm/yyy (ddd)\" for ease of reference.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Communication events with parsed date and time\ncomm_events <- mc3_nodes_final %>%\n  filter(type == \"Event\", sub_type == \"Communication\") %>%\n  mutate(timestamp = ymd_hms(timestamp)) %>%\n  filter(!is.na(timestamp)) %>%\n  mutate(\n    hour = hour(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")  # e.g., \"19/03/2040 (Tue)\"\n  )\n```\n:::\n\n\n### Step 2: Visualize the Communication Volume for Analysis\n\n#### **4.1 - Bar Plot of daily communication volume over the 2 weeks period:**\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Step 1: Prepare daily message volume data\ndaily_message_volume <- mc3_nodes_final %>%\n  filter(type == \"Event\", sub_type == \"Communication\") %>%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    date = as.Date(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")\n  ) %>%\n  group_by(date, date_label) %>%\n  summarise(message_count = n(), .groups = \"drop\") %>%\n  arrange(date)\n\n# Step 2: Compute average and total message count\navg_msg_count <- mean(daily_message_volume$message_count)\ntotal_msg_count <- sum(daily_message_volume$message_count)\n\n# Step 3: Plot bar chart with average + total labels\nggplot(daily_message_volume, aes(x = date_label, y = message_count)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text(\n    aes(label = message_count),\n    vjust = -0.3,\n    size = 2.5,\n    color = \"grey40\"\n  ) +\n  geom_hline(yintercept = avg_msg_count, color = \"red\", linetype = \"dashed\", size = 1.2) +\n  annotate(\n    \"label\", x = 1, y = avg_msg_count + 2,\n    label = paste(\"Average =\", round(avg_msg_count, 1)),\n    color = \"red\", fill = \"grey90\",\n    label.size = 0, hjust = -0.2, vjust = 3\n  ) +\n  annotate(\n    \"label\", x = nrow(daily_message_volume), y = max(daily_message_volume$message_count) + 5,\n    label = paste(\"Total =\", total_msg_count),\n    color = \"black\", fill = \"lightgrey\",\n    label.size = 0.3, hjust = 1.1, vjust = 1\n  ) +\n  labs(\n    title = \"Daily Radio Communication Volume\",\n    x = \"Date\",\n    y = \"Message Count\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n```\n:::\n\n\n#### **4.2 - Interactive Table of daily communication volume variation(message count)**\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(DT)\n\n# Daily message volume with comparisons\ndaily_message_volume <- mc3_nodes_final %>%\n  filter(type == \"Event\", sub_type == \"Communication\") %>%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    date = as.Date(timestamp),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\")\n  ) %>%\n  group_by(date, date_label) %>%\n  summarise(message_count = n(), .groups = \"drop\") %>%\n  arrange(date) %>%\n  mutate(\n    change_from_prev = message_count - lag(message_count),\n    pct_change_from_prev = round((message_count - lag(message_count)) / lag(message_count) * 100, 2)\n  )\n\ndatatable(\n  daily_message_volume %>% select(-date),  # remove raw date if not needed\n  caption = \"Daily Message Volume with Day-over-Day Change\",\n  options = list(pageLength = 14, order = list(list(0, 'asc'))),\n  rownames = FALSE\n)\n```\n:::\n\n\n#### **4.3a - Heat Map of hourly message volume for each day over the 2 weeks period:**\n\nThis heat map is interactive and you may choose to hover on the tile to display the **date, time, and message count**\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(forcats)\nlibrary(plotly)\n\n# Step 1: Reconstruct sender‚Äìreceiver‚Äìtimestamp structure\ncomm_events_raw <- mc3_nodes_final %>%\n  filter(type == \"Event\", sub_type == \"Communication\") %>%\n  select(event_id = id, timestamp) %>%\n  mutate(timestamp = ymd_hms(timestamp),\n         hour = hour(timestamp),\n         date_label = format(timestamp, \"%d/%m/%Y (%a)\"))\n\n# Step 2: Get sender (sent) and receiver (received) links\ncomm_edges_sent <- mc3_edges_cleaned %>%\n  filter(type == \"sent\") %>%\n  select(event_id = to_id, sender_id = from_id)\n\ncomm_edges_recv <- mc3_edges_cleaned %>%\n  filter(type == \"received\") %>%\n  select(event_id = from_id, receiver_id = to_id)\n\n# Step 3: Join all together into sender‚Äìreceiver‚Äìtimestamp\ncomm_links <- comm_events_raw %>%\n  left_join(comm_edges_sent, by = \"event_id\") %>%\n  left_join(comm_edges_recv, by = \"event_id\") %>%\n  left_join(mc3_nodes_cleaned %>% select(sender_id = id, sender_label = label), by = \"sender_id\") %>%\n  left_join(mc3_nodes_cleaned %>% select(receiver_id = id, receiver_label = label), by = \"receiver_id\")\n\n# Step 4: Aggregate total messages per hour/day\ncomm_heatmap <- comm_links %>%\n  group_by(date_label, hour) %>%\n  summarise(\n    count = n(),\n    top_sender = names(sort(table(sender_label), decreasing = TRUE))[1],\n    sender_count = max(table(sender_label)),\n    top_receiver = names(sort(table(receiver_label), decreasing = TRUE))[1],\n    receiver_count = max(table(receiver_label)),\n    .groups = \"drop\"\n  ) %>%\n  mutate(\n    tooltip = paste0(\n      \"üìÖ Date: \", date_label,\n      \"<br>‚è∞ Hour: \", sprintf(\"%02d:00\", hour),\n      \"<br>üì® Messages: \", count,\n      \"<br>üî¥ Top Sender: \", top_sender, \" (\", sender_count, \")\",\n      \"<br>üü¢ Top Receiver: \", top_receiver, \" (\", receiver_count, \")\"\n    )\n  )\n\n# Step 5: Static ggplot\np <- ggplot(comm_heatmap, aes(\n  x = hour,\n  y = fct_rev(factor(date_label)),\n  fill = count,\n  text = tooltip\n)) +\n  geom_tile(color = \"white\") +\n  scale_fill_viridis_c(option = \"inferno\", direction = -1, name = \"Message Count\") +\n  scale_x_continuous(\n    breaks = 0:23,\n    labels = function(x) sprintf(\"%02d:00\", x)\n  ) +\n  labs(\n    title = \"Hourly Heatmap of Radio Communications by Day\",\n    x = \"Hour of Day\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 10) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid = element_blank()\n  )\n\n# Step 6: Make interactive\nggplotly(p, tooltip = \"text\")\n```\n:::\n\n\nWe will increase the resolution to half-hour time slots.\n\n#### **4.4b - Heat Map of half-hourly message volume for each day over the 2 weeks period:**\n\nThis heat map is interactive and you may choose to hover on the tile to display the **date, time, and message count**.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(forcats)\nlibrary(plotly)\n\n# Step 1: Fix sender and receiver edges\ncomm_edges_sent <- mc3_edges_cleaned %>%\n  filter(type == \"sent\") %>%\n  select(event_id = to_id, sender_id = from_id)\n\ncomm_edges_recv <- mc3_edges_cleaned %>%\n  filter(type == \"received\") %>%\n  select(event_id = from_id, receiver_id = to_id)  # ‚úÖ fixed receiver_id\n\n# Step 2: Reconstruct sender‚Äìreceiver‚Äìevent linkage\ncomm_events_raw <- mc3_nodes_final %>%\n  filter(type == \"Event\", sub_type == \"Communication\") %>%\n  select(event_id = id, timestamp) %>%\n  mutate(\n    timestamp = ymd_hms(timestamp),\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = hour + ifelse(minute < 30, 0, 0.5),\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\"),\n    time_label = sprintf(\"%02d:%02d\", floor(time_bin), ifelse(time_bin %% 1 == 0, 0, 30))\n  )\n\n# Step 3: Join to get sender/receiver labels\ncomm_links <- comm_events_raw %>%\n  left_join(comm_edges_sent, by = \"event_id\") %>%\n  left_join(comm_edges_recv, by = \"event_id\") %>%\n  left_join(mc3_nodes_cleaned %>% select(id, sender_label = label), by = c(\"sender_id\" = \"id\")) %>%\n  left_join(mc3_nodes_cleaned %>% select(id, receiver_label = label), by = c(\"receiver_id\" = \"id\"))\n\n# Step 4: Aggregate by half-hour + label top actors\ncomm_heatmap <- comm_links %>%\n  group_by(date_label, time_bin, time_label) %>%\n  summarise(\n    count = n(),\n    top_sender = names(sort(table(sender_label), decreasing = TRUE))[1],\n    sender_count = max(table(sender_label)),\n    top_receiver = names(sort(table(receiver_label), decreasing = TRUE))[1],\n    receiver_count = max(table(receiver_label)),\n    .groups = \"drop\"\n  ) %>%\n  mutate(\n    tooltip = paste0(\n      \"üìÖ Date: \", date_label,\n      \"<br>üïí Time: \", time_label,\n      \"<br>üì® Messages: \", count,\n      \"<br>üî¥ Top Sender: \", top_sender, \" (\", sender_count, \")\",\n      \"<br>üü¢ Top Receiver: \", top_receiver, \" (\", receiver_count, \")\"\n    )\n  )\n\n# Step 5: ggplot\np <- ggplot(comm_heatmap, aes(x = time_bin, y = fct_rev(factor(date_label)), fill = count, text = tooltip)) +\n  geom_tile(color = \"white\") +\n  scale_fill_viridis_c(\n    option = \"inferno\",\n    direction = -1,\n    name = \"Message Count\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  labs(\n    title = \"Half-Hourly Heatmap of Radio Communications by Day\",\n    x = \"Time of Day\",\n    y = NULL\n  ) +\n  theme_minimal(base_size = 10) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid = element_blank()\n  )\n\n# Step 6: Convert to interactive Plotly plot\nggplotly(p, tooltip = \"text\")\n```\n:::\n\n\n#### **4.4c - Density plot of Daily half-hourly message volume over the 2 weeks period:**\n\nThe faceted density plot that shows the **distribution of communication events by time of day**, broken down for each day in the dataset. It helps to visually detect **temporal communication patterns**, intensity, and consistency over multiple days.\n\n::: panel-tabset\n### Overview of the 2 week period\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Step 1: Preprocess communication events\ncomm_events <- mc3_nodes_final %>%\n  filter(type == \"Event\", sub_type == \"Communication\") %>%\n  mutate(timestamp = ymd_hms(timestamp)) %>%\n  filter(!is.na(timestamp)) %>%\n  mutate(\n    date_label = format(timestamp, \"%d/%m/%Y (%a)\"),\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = hour + ifelse(minute < 30, 0, 0.5)\n  )\n\n# Step 2: Summarise daily medians and counts\ndaily_stats <- comm_events %>%\n  group_by(date_label) %>%\n  summarise(\n    median_time = median(time_bin),\n    msg_count = n(),\n    .groups = \"drop\"\n  )\n\n# Step 3: Plot\nggplot(comm_events, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = daily_stats, aes(xintercept = median_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(\n    data = daily_stats,\n    aes(x = 20.5, y = 0.25, label = paste(\"Total:\", msg_count)),\n    inherit.aes = FALSE,\n    size = 3,\n    color = \"grey20\",\n    hjust = 1\n  ) +\n  facet_wrap(~ date_label, ncol = 4) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = NULL  # suppress all x-axis labels\n  ) +\n  labs(\n    title = \"Daily Communication Patterns (Half-Hourly)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\"),\n    panel.grid.minor = element_blank()\n  )\n```\n:::\n\n\n### Day 1 - 01/10/2040\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Filter for selected date\ndaily_data <- filter(comm_events, date_label == \"01/10/2040 (Mon)\")\n\n# Build density data to find full curve\ndensity_data <- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ¬±10% of the maximum density\nmax_y <- max(density_data$y)\npeak_threshold <- 0.9 * max_y\n\nmajor_peaks <- density_data %>%\n  filter(y >= peak_threshold) %>%\n  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %>%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count <- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n```\n:::\n\n\n### Day 2 - 02/10/2040\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Filter for selected date\ndaily_data <- filter(comm_events, date_label == \"02/10/2040 (Tue)\")\n\n# Build density data to find full curve\ndensity_data <- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ¬±10% of the maximum density\nmax_y <- max(density_data$y)\npeak_threshold <- 0.9 * max_y\n\nmajor_peaks <- density_data %>%\n  filter(y >= peak_threshold) %>%\n  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %>%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count <- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n```\n:::\n\n\n### Day 3 - 03/10/2040\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Filter for selected date\ndaily_data <- filter(comm_events, date_label == \"03/10/2040 (Wed)\")\n\n# Build density data to find full curve\ndensity_data <- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ¬±10% of the maximum density\nmax_y <- max(density_data$y)\npeak_threshold <- 0.9 * max_y\n\nmajor_peaks <- density_data %>%\n  filter(y >= peak_threshold) %>%\n  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %>%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count <- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n```\n:::\n\n\n### Day 4 - 04/10/2040\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Filter for selected date\ndaily_data <- filter(comm_events, date_label == \"04/10/2040 (Thu)\")\n\n# Build density data to find full curve\ndensity_data <- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ¬±10% of the maximum density\nmax_y <- max(density_data$y)\npeak_threshold <- 0.9 * max_y\n\nmajor_peaks <- density_data %>%\n  filter(y >= peak_threshold) %>%\n  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %>%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count <- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n```\n:::\n\n\n### Day 5 - 05/10/2040\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Filter for selected date\ndaily_data <- filter(comm_events, date_label == \"05/10/2040 (Fri)\")\n\n# Build density data to find full curve\ndensity_data <- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ¬±10% of the maximum density\nmax_y <- max(density_data$y)\npeak_threshold <- 0.9 * max_y\n\nmajor_peaks <- density_data %>%\n  filter(y >= peak_threshold) %>%\n  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %>%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count <- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n```\n:::\n\n\n### Day 6 - 06/10/2040\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Filter for selected date\ndaily_data <- filter(comm_events, date_label == \"06/10/2040 (Sat)\")\n\n# Build density data to find full curve\ndensity_data <- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ¬±10% of the maximum density\nmax_y <- max(density_data$y)\npeak_threshold <- 0.9 * max_y\n\nmajor_peaks <- density_data %>%\n  filter(y >= peak_threshold) %>%\n  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %>%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count <- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n```\n:::\n\n\n### Day 7 - 07/10/2040\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Filter for selected date\ndaily_data <- filter(comm_events, date_label == \"07/10/2040 (Sun)\")\n\n# Build density data to find full curve\ndensity_data <- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ¬±10% of the maximum density\nmax_y <- max(density_data$y)\npeak_threshold <- 0.9 * max_y\n\nmajor_peaks <- density_data %>%\n  filter(y >= peak_threshold) %>%\n  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %>%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count <- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n```\n:::\n\n\n### Day 8 - 08/10/2040\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Filter for selected date\ndaily_data <- filter(comm_events, date_label == \"08/10/2040 (Mon)\")\n\n# Build density data to find full curve\ndensity_data <- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ¬±10% of the maximum density\nmax_y <- max(density_data$y)\npeak_threshold <- 0.9 * max_y\n\nmajor_peaks <- density_data %>%\n  filter(y >= peak_threshold) %>%\n  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %>%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count <- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n```\n:::\n\n\n### Day 9 - 09/10/2040\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Filter for selected date\ndaily_data <- filter(comm_events, date_label == \"09/10/2040 (Tue)\")\n\n# Build density data to find full curve\ndensity_data <- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ¬±10% of the maximum density\nmax_y <- max(density_data$y)\npeak_threshold <- 0.9 * max_y\n\nmajor_peaks <- density_data %>%\n  filter(y >= peak_threshold) %>%\n  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %>%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count <- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n```\n:::\n\n\n### Day 10 - 10/10/2040\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Filter for selected date\ndaily_data <- filter(comm_events, date_label == \"10/10/2040 (Wed)\")\n\n# Build density data to find full curve\ndensity_data <- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ¬±10% of the maximum density\nmax_y <- max(density_data$y)\npeak_threshold <- 0.9 * max_y\n\nmajor_peaks <- density_data %>%\n  filter(y >= peak_threshold) %>%\n  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %>%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count <- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n```\n:::\n\n\n### Day 11 - 11/10/2040\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Filter for selected date\ndaily_data <- filter(comm_events, date_label == \"11/10/2040 (Thu)\")\n\n# Build density data to find full curve\ndensity_data <- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ¬±10% of the maximum density\nmax_y <- max(density_data$y)\npeak_threshold <- 0.9 * max_y\n\nmajor_peaks <- density_data %>%\n  filter(y >= peak_threshold) %>%\n  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %>%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count <- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n```\n:::\n\n\n### Day 12 - 12/10/2040\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Filter for selected date\ndaily_data <- filter(comm_events, date_label == \"12/10/2040 (Fri)\")\n\n# Build density data to find full curve\ndensity_data <- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ¬±10% of the maximum density\nmax_y <- max(density_data$y)\npeak_threshold <- 0.9 * max_y\n\nmajor_peaks <- density_data %>%\n  filter(y >= peak_threshold) %>%\n  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %>%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count <- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n```\n:::\n\n\n### Day 13 - 13/10/2040\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Filter for selected date\ndaily_data <- filter(comm_events, date_label == \"13/10/2040 (Sat)\")\n\n# Build density data to find full curve\ndensity_data <- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ¬±10% of the maximum density\nmax_y <- max(density_data$y)\npeak_threshold <- 0.9 * max_y\n\nmajor_peaks <- density_data %>%\n  filter(y >= peak_threshold) %>%\n  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %>%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count <- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n```\n:::\n\n\n### Day 14 - 14/10/2040\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Filter for selected date\ndaily_data <- filter(comm_events, date_label == \"14/10/2040 (Sun)\")\n\n# Build density data to find full curve\ndensity_data <- ggplot_build(\n  ggplot(daily_data, aes(x = time_bin)) +\n    geom_density()\n)$data[[1]]\n\n# Identify peaks within ¬±10% of the maximum density\nmax_y <- max(density_data$y)\npeak_threshold <- 0.9 * max_y\n\nmajor_peaks <- density_data %>%\n  filter(y >= peak_threshold) %>%\n  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins\n  summarise(\n    peak_time = x[which.max(y)],\n    peak_density = max(y),\n    .groups = \"drop\"\n  ) %>%\n  mutate(\n    label = sprintf(\"Peak: %02d:%02d\",\n                    floor(peak_time),\n                    ifelse(peak_time %% 1 == 0, 0, 30))\n  )\n\n# Message count\nmsg_count <- nrow(daily_data)\n\n# Final plot\nggplot(daily_data, aes(x = time_bin)) +\n  geom_density(fill = \"steelblue\", alpha = 0.7) +\n  geom_vline(data = major_peaks, aes(xintercept = peak_time),\n             color = \"red\", linetype = \"dashed\", linewidth = 0.6) +\n  geom_text(data = major_peaks,\n            aes(x = peak_time, y = 0.23, label = label),\n            color = \"red\", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +\n  annotate(\"text\", x = 20.5, y = 0.25,\n           label = paste(\"Total messages communicated:\", msg_count),\n           hjust = 1, size = 4, color = \"grey30\") +\n  labs(\n    title = \"Half-Hourly Communication Density (Multiple Peaks Highlighted)\",\n    x = \"Time of Day\",\n    y = \"Density\"\n  ) +\n  scale_x_continuous(\n    breaks = seq(0, 23.5, by = 0.5),\n    labels = function(x) sprintf(\"%02d:%02d\", floor(x), ifelse(x %% 1 == 0, 0, 30))\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    strip.text = element_text(face = \"bold\")\n  )\n```\n:::\n\n:::\n\nüìà **Insights This Visualization Offers**\n\n### Step 3: Plot Combined Hourly and Half-hourly Communication Volume\n\n**Bar Plot of combined hourly message volume over the 2 weeks period:**\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Prepare data\ncomm_hourly <- comm_events %>%\n  count(hour) %>%\n  mutate(\n    hour_label = sprintf(\"%02d:00\", hour),  # Format to hh:mm\n    percent = n / sum(n)\n  )\n\n# Plot\nggplot(comm_hourly, aes(x = hour_label, y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text_repel(\n    aes(label = paste0(n, \" (\", percent(percent, accuracy = 1), \")\")),\n    nudge_y = 3,\n    size = 2.5,\n    direction = \"y\",\n    max.overlaps = Inf\n  ) +\n  labs(\n    title = \"Overall Hourly Communication Volume\",\n    x = \"Time of Day (hh:mm)\",\n    y = \"Message Count\"\n  ) +\n  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n```\n:::\n\n\n**Bar Plot of combined half-hourly message volume in the 2 weeks period.**\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ncomm_events <- mc3_nodes_final %>%\n  filter(type == \"Event\", sub_type == \"Communication\") %>%\n  mutate(timestamp = ymd_hms(timestamp)) %>%\n  filter(!is.na(timestamp)) %>%\n  mutate(\n    hour = hour(timestamp),\n    minute = minute(timestamp),\n    time_bin = sprintf(\"%02d:%02d\", hour, ifelse(minute < 30, 0, 30))\n  )\n\ncomm_halfhour <- comm_events %>%\n  count(time_bin) %>%\n  mutate(percent = n / sum(n))\n\nggplot(comm_halfhour, aes(x = time_bin, y = n)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  geom_text_repel(\n    aes(label = paste0(n, \" (\", percent(percent, accuracy = 1), \")\")),\n    nudge_y = 3,\n    size = 2.5,\n    direction = \"y\",\n    max.overlaps = Inf\n  ) +\n  labs(\n    title = \"Overall Half-Hourly Communication Volume\",\n    x = \"Time of Day (hh:mm)\",\n    y = \"Message Count\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    plot.title = element_text(face = \"bold\")\n  )\n```\n:::\n\n\n::: callout-tip\n## 1a. What are the identifiable daily temporal patterns in communications?\n\n1.  The daily communication volume fluctuates slightly between 34 and 49 messages, with an average of approximately 42 messages per day, highlighting a stable overall activity level. Notably, the highest volume occurs on 11th October (49 messages), immediately following the lowest volume the day before on 10th October (34 messages)‚Äîa sharp rebound that may signal a response to specific events or operational needs. Despite these fluctuations, the system maintains a consistent tempo across the two weeks.\n\n2.  The temporal analysis using both the heat map and time series plots reveals a pronounced morning-centric communication rhythm. The vast majority of radio traffic is concentrated between 9:00 AM and 11:30 AM, with the most intense peaks typically occurring between 10:00 and 11:00 AM. With reference to the Density plot of Daily half-hourly message volume, of the 14 days, we see message density peaks at 10:30 AM on 9 days, while on 3 days, it peaks at 12:30 PM.\n\n3.  For instance if we were to based in on the hourly plot, 5th October (Fri) and 11th October (Thu) both register their highest single-hour counts at 10:00 AM at 24 and 21 messages respectively. Communication activity drops off steeply after lunchtime, with more than 90% of the days showing little to no activity after 2:30 PM. This pattern suggests a highly structured daily workflow, where key decisions and coordination are front-loaded in the day. Importantly, the hourly heat map also indicates that this routine holds across both weekdays and weekends‚Äîcommunication volumes and peak hours remain similar, underlining the operational regularity of the group regardless of the day of week.\n:::\n\n::: callout-tip\n## 1b. How do these patterns shift over the two weeks of observations?\n\n1.  Over the two-week period, while the timing and structure of communication peaks remain broadly consistent, there are subtle shifts in both intensity and timing. Some days, such as 3rd, 5th, 11th and 12th October, see particularly high spikes in the mid-morning, which may correspond to critical events, decision points, or heightened urgency. The sharp dip on October 8th and 13th, immediately after a period of \"surge\" (3rd - 7th and 9th to 12th October), points to possible responses to interruptions, lulls, or triggering incidents. Overall, although the daily messaging routine is remarkably stable, these bursts and brief lulls provide clues to changing circumstances or stress points in the operation‚Äîan analytical signal that warrants closer inspection of event logs or external triggers for those dates.\n\n2.  Another notable change in the communication pattern is observed during the weekends. In the first week, weekend communication peaks occurred earlier, typically between 10:00 AM and 11:30 AM, closely mirroring the weekday rhythm. However, in the second week, the weekend peaks shifted noticeably later, with the highest message volumes concentrated around 12:00 PM and 1:00 PM. This shift not only marks a departure from the otherwise stable early-morning communication structure but also suggests an adaptive or reactive operational schedule‚Äîpotentially in response to evolving events, increased coordination needs, or changing priorities as the observation period progressed. The contrast between the two weekends is clear in the heatmap, underscoring the importance of monitoring such shifts as possible indicators of underlying changes in group behavior or external pressures.\n:::\n\n## 5 - Task 1c: Focus on a Particular Entity - \"Nadia Conti\"\n\n::: callout-note\n## VAST Challenge Task & Question 1c\n\nClepper found that messages frequently came in at around the same time each day.\n\n1.  Focus on a specific entity and use this information to determine who has influence over them.\n:::\n\n### 5.1 **-** Data Preparation for \"Nadia Conti\" Influence Analysis\n\nWe first extracted the relevant communication edges from the dataset, pairing ‚Äúsent‚Äù and ‚Äúreceived‚Äù communication events to form entity-to-entity links. We retained only those edges where both nodes represent real-world entities (Person, Organization, Vessel, Group, or Location), ensuring that our analysis focuses on the meaningful actors in the Oceanus network.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Extract sent and received communication event edges\nsent_edges <- mc3_edges_cleaned %>%\n  filter(type == \"sent\") %>%\n  select(source_entity = from_id, event = to_id)\n\nreceived_edges <- mc3_edges_cleaned %>%\n  filter(type == \"received\") %>%\n  select(event = from_id, target_entity = to_id)\n\n# Pair sent and received to form communication edges\npaired_edges <- sent_edges %>%\n  inner_join(received_edges, by = \"event\") %>%\n  select(from = source_entity, to = target_entity)\n\n# Add unmatched sent and received edges (optional, for completeness)\nsingle_sent_edges <- sent_edges %>%\n  select(from = source_entity, to = event)\nsingle_received_edges <- received_edges %>%\n  select(from = event, to = target_entity)\n\nall_edges <- bind_rows(paired_edges, single_sent_edges, single_received_edges) %>%\n  distinct()\n\n# Identify entity nodes (Person, Organization, Vessel, Group, Location)\nentity_ids <- mc3_nodes_cleaned %>%\n  filter(sub_type %in% c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\")) %>%\n  pull(id) %>% as.character()\n\nentity_edges <- all_edges %>%\n  filter(as.character(from) %in% entity_ids, as.character(to) %in% entity_ids)\n\nentity_nodes <- mc3_nodes_cleaned %>%\n  filter(sub_type %in% c(\"Person\", \"Organization\", \"Vessel\", \"Group\", \"Location\")) %>%\n  select(id, label, sub_type)\n```\n:::\n\n\n### 5.2 **-** Build the Global Network and Compute Centrality\n\nUsing these cleaned and filtered edges and nodes, we built a global directed graph representing the Oceanus community. We then computed key network centrality metrics for each node‚ÄîPageRank, betweenness, and degree‚Äîquantifying the influence and connectivity of every entity in the overall network.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(igraph)\n\ng <- graph_from_data_frame(d = entity_edges, vertices = entity_nodes, directed = TRUE)\n\n# Compute centralities\nV(g)$pagerank <- page_rank(g)$vector\nV(g)$betweenness <- betweenness(g)\nV(g)$degree <- degree(g)\n```\n:::\n\n\n### 5.3 **-** Extract \"Nadia Conti\" Ego Network (2-hop Neighbourhood)\n\nFocusing on \"Nadia Conti\", we identified her node and extracted her two-step ego network, capturing both direct and indirect connections within the broader network. This local subgraph reveals Nadia‚Äôs immediate sphere of influence and the key players connected to her.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nnadia_label <- \"Nadia Conti\"\ntarget_index <- which(V(g)$label == nadia_label)\n\nego_graph <- make_ego_graph(g, order = 2, nodes = target_index, mode = \"all\")[[1]]\n```\n:::\n\n\n### 5.4 **-** Visualize Nadia Conti‚Äôs Ego Network (Interactive)\n\nWe visualized Nadia‚Äôs ego network using node size, shape, and color to represent centrality and entity type. We also summarized centrality metrics in clear tables, ranking all ego network members by PageRank, Betweenness, and Degree. This allows for direct identification of the most influential, best-connected, and most strategic actors in Nadia Conti‚Äôs communication environment.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nnodes_df <- data.frame(\n  id = V(ego_graph)$name,\n  label = V(ego_graph)$label,\n  group = V(ego_graph)$sub_type,\n  title = paste0(\"<b>\", V(ego_graph)$label, \"</b><br>\",\n                 \"Degree: \", round(V(ego_graph)$degree, 2), \"<br>\",\n                 \"Betweenness: \", round(V(ego_graph)$betweenness, 2), \"<br>\",\n                 \"PageRank: \", round(V(ego_graph)$pagerank, 4)),\n  shape = ifelse(V(ego_graph)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_graph)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_graph)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_graph)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  value = V(ego_graph)$pagerank * 30 + 5\n)\n\nedges_df <- as_data_frame(ego_graph, what = \"edges\") %>%\n  rename(from = from, to = to)\n\nlibrary(visNetwork)\nvisNetwork(nodes_df, edges_df, width = \"100%\", height = \"700px\") %>%\n  visNodes(scaling = list(min = 5, max = 30)) %>%\n  visEdges(\n    arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)),\n    color = list(color = \"gray\")\n  ) %>%\n  visOptions(\n    highlightNearest = TRUE,\n    nodesIdSelection = TRUE,\n    manipulation = FALSE\n  ) %>%\n  visInteraction(\n    dragNodes = FALSE,\n    dragView = FALSE,\n    zoomView = FALSE\n  ) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 1818)\n```\n:::\n\n\n::: callout-note\n## Global and Ego-Network Structure\n\nThe overview network visualization reveals that **Nadia Conti** is centrally embedded in the Oceanus communication web, maintaining direct and indirect connections with major actors such as Neptune (Vessel), V. Miesel Shipping (Organization), Elise (Person), and others. The use of color and shape coding in the network allows for quick identification of the different types of entities in Nadia‚Äôs influence neighborhood.\n:::\n\n### 5.5 **-** Centrality Tables for Nadia‚Äôs Ego Network\n\nOn both the global and Nadia-focused ego networks, we computed standard network centrality metrics for all nodes:\n\n-   **PageRank** (overall influence),\n-   **Betweenness** (information brokerage/intermediary role), and\n-   **Degree** (number of direct connections).\n\nThese measures quantify the importance and structural roles of each entity relative to Nadia and the broader community.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# PageRank table\npagerank_df <- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  pagerank = round(V(ego_graph)$pagerank, 4)\n) %>% arrange(desc(pagerank))\n\n# Betweenness table\nbetweenness_df <- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  betweenness = round(V(ego_graph)$betweenness, 2)\n) %>% arrange(desc(betweenness))\n\n# Degree table\ndegree_df <- data.frame(\n  label = V(ego_graph)$label,\n  sub_type = V(ego_graph)$sub_type,\n  degree = V(ego_graph)$degree\n) %>% arrange(desc(degree))\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::kable(pagerank_df, caption = \"PageRank Centrality (Nadia's Ego Network)\")\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::kable(betweenness_df, caption = \"Betweenness Centrality (Nadia's Ego Network)\")\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::kable(degree_df, caption = \"Degree Centrality (Nadia's Ego Network)\")\n```\n:::\n\n\n::: callout-note\n## Centrality Metrics and Direct & Indirect Influences\n\nBy calculating centrality metrics within Nadia‚Äôs two-hop ego network, we observe that the most influential nodes in her environment‚Äîby PageRank, betweenness, and degree‚Äîare Neptune, V. Miesel Shipping, and Elise. Nadia herself consistently ranks among the top nodes by these measures, highlighting her role as both an influencer and an information bridge. Entities such as Neptune and V. Miesel Shipping, which also score highly in centrality, exert considerable influence over Nadia‚Äôs information flow and access to other parts of the network.\n\nDegree centrality analysis shows Nadia maintains multiple direct connections, particularly with other highly active nodes, ensuring she is closely linked to key hubs in the network. Betweenness centrality further reveals that Nadia is not only well-connected but also acts as an important intermediary, facilitating communication between otherwise distant parts of the network. PageRank confirms that her immediate environment is composed of actors with significant structural power, increasing the likelihood that Nadia is both influenced by, and exerts influence upon, the most pivotal players in Oceanus.\n:::\n\n#### **5.5.1 - PageRank for Nadia Conti**\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nlibrary(igraph)\nlibrary(visNetwork)\n\n# -- Build the global network g as in your earlier code (using your entity_nodes/entity_edges) --\n\ng <- graph_from_data_frame(\n  d = entity_edges, \n  vertices = entity_nodes, \n  directed = TRUE\n)\n\n# -- Get Nadia's index in g --\nnadia_label <- \"Nadia Conti\"\ntarget_index <- which(V(g)$label == nadia_label)\n\n# -- Extract Nadia's 1-hop ego network (all direct neighbors) --\nego_1 <- make_ego_graph(g, order = 1, nodes = target_index, mode = \"all\")[[1]]\n\n\n# 1. Compute PageRank for the ego network\nV(ego_1)$pagerank <- page_rank(ego_1)$vector\n\n# 2. Prepare node data frame with your consistent color scheme\nnodes_df_pagerank <- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"<b>\", V(ego_1)$label, \"</b><br>PageRank: \", round(V(ego_1)$pagerank, 4)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$pagerank * 30 + 5\n)\n\n# 3. Prepare edges\nedges_df <- as_data_frame(ego_1, what = \"edges\") %>%\n  rename(from = from, to = to)\n\n# 4. Plot with visNetwork\nvisNetwork(nodes_df_pagerank, edges_df, width = \"100%\", height = \"400px\") %>%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_pagerank$color, border = \"black\"),\n    shape = nodes_df_pagerank$shape\n  ) %>%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %>%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %>%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 1818)\n```\n:::\n\n\n#### **5.5.2 - Betweenness for Nadia Conti**\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# 1. Compute Betweenness for the ego network\nV(ego_1)$betweenness <- betweenness(ego_1, directed = TRUE)\n\n# 2. Prepare node data frame\nnodes_df_betweenness <- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"<b>\", V(ego_1)$label, \"</b><br>Betweenness: \", round(V(ego_1)$betweenness, 2)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$betweenness * 2 + 5\n)\n\n# 3. Edges (same as before)\n# edges_df already prepared\n\n# 4. Plot\nvisNetwork(nodes_df_betweenness, edges_df, width = \"100%\", height = \"400px\") %>%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_betweenness$color, border = \"black\"),\n    shape = nodes_df_betweenness$shape\n  ) %>%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %>%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %>%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 1818)\n```\n:::\n\n\n#### **5.5.3 - Degree for Nadia Conti**\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# 1. Compute Degree for the ego network\nV(ego_1)$degree <- degree(ego_1, mode = \"all\")\n\n# 2. Prepare node data frame\nnodes_df_degree <- data.frame(\n  id = V(ego_1)$name,\n  label = V(ego_1)$label,\n  group = V(ego_1)$sub_type,\n  title = paste0(\"<b>\", V(ego_1)$label, \"</b><br>Degree: \", round(V(ego_1)$degree, 2)),\n  shape = ifelse(V(ego_1)$sub_type == \"Person\", \"dot\",\n                 ifelse(V(ego_1)$sub_type == \"Organization\", \"square\",\n                        ifelse(V(ego_1)$sub_type == \"Vessel\", \"triangle\",\n                               ifelse(V(ego_1)$sub_type == \"Group\", \"star\", \"diamond\")))),\n  color = case_when(\n    V(ego_1)$sub_type == \"Person\" ~ \"#2ca5ff\",\n    V(ego_1)$sub_type == \"Organization\" ~ \"#f5ee15\",\n    V(ego_1)$sub_type == \"Vessel\" ~ \"#FB7E81\",\n    V(ego_1)$sub_type == \"Group\" ~ \"#25e158\",\n    V(ego_1)$sub_type == \"Location\" ~ \"#ec4bff\",\n    TRUE ~ \"black\"\n  ),\n  value = V(ego_1)$degree * 5 + 5\n)\n\n# 3. Edges (same as before)\n# edges_df already prepared\n\n# 4. Plot\nvisNetwork(nodes_df_degree, edges_df, width = \"100%\", height = \"400px\") %>%\n  visNodes(\n    scaling = list(min = 5, max = 30),\n    color = list(background = nodes_df_degree$color, border = \"black\"),\n    shape = nodes_df_degree$shape\n  ) %>%\n  visEdges(arrows = list(to = list(enabled = TRUE, scaleFactor = 0.3)), color = list(color = \"gray\")) %>%\n  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE, manipulation = FALSE) %>%\n  visInteraction(dragNodes = FALSE, dragView = FALSE, zoomView = FALSE) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 1818)\n```\n:::\n\n\n::: callout-tip\n## 1c. With a focus on \"Nadia Conti\",  the visuals above could determine who has influence over this person.\n\n1.  Degree centrality reveals that Nadia Conti is well-connected within her local network, with a degree of 17. However, she is not the most connected node; vessels such as Mako (37), Reef Guardian (27), and Remora (21), as well as organizations like Oceanus City Council (28) and V. Miesel Shipping (19), have even higher degrees. This indicates that while Nadia is an important hub, her sphere of direct interaction is embedded within a dense mesh of other highly connected entities.\n\n2.  Several other individuals (e.g., Davis with 16, Boss with 13, Mrs. Money with 12) and vessels (e.g., Neptune with 19, Sentinel with 16) also play significant roles in Nadia‚Äôs network. The presence of organizations (e.g., Green Guardians, Sailor Shifts Team), multiple vessels, and key persons shows that **Nadia‚Äôs environment is both diverse and robust**.\n\n3.  **Direct Connections**\n\n    These direct connections are clearly shown as nodes that have edges (arrows) going into or out of Nadia Conti‚Äôs node in the network diagrams. Nadia Conti directly connects to several core entities across different types:\n\n    -   **People:** Elise, Liam Thorne, Davis, Rodriguez\n    -   **Organization:** V. Miesel Shipping, Oceanus City Council, Sailor Shifts Team\n    -   **Vessel:** Neptune, Marlin, Remora, Sentinel\n    -   **Location:** Haacklee Harbor\n\n    **Interpretation:**\n    The PageRank, Betweenness, and Degree centrality plots all consistently show **Nadia Conti as a major hub**, with a large node size reflecting her high centrality. Her immediate network includes influential vessels (Neptune, Remora), organizations (V. Miesel Shipping, Oceanus City Council), and several persons (Elise, Davis, Rodriguez).\n\n    Nadia‚Äôs position suggests she is a **key connector and influencer** but is herself surrounded by even larger hubs, particularly among vessels and organizations. Her ability to influence‚Äîand be influenced‚Äîis amplified by these connections, as these high-degree entities are likely sources and conduits of critical information and operational coordination. This structure points to a tightly interwoven community, where central actors such as Mako, Oceanus City Council, and V. Miesel Shipping may exert the most substantial influence over Nadia‚Äôs access to information, resources, and strategic decisions.\n:::\n",
    "supporting": [
      "Take-Home_Ex02_MC3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}