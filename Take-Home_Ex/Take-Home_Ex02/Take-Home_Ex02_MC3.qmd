---
title: "Take-Home Assignment 2"
description: ""
author: "David Chiam"
date: "22 May 2025"
date-modified: "31 May 2025"
format: html
editor: visual
execute: 
  eval: true
  echo: true
  warning: false
  freeze: true
---

# **Take Home Assignment 2 on Mini-Challenge 3**

## **1 - Getting Started**

### 1.1 - Load the R packages for this assignment

For the purpose of this assignment, five R packages will be used. They are tidyverse, jsonlite, tidygraph, ggraph and SmartEDA.

In the code chunk below, p_load() of pacman package is used to load the R packages into R environment.

```{r}

pacman::p_load(tidyverse, jsonlite, 
               tidygraph, ggraph, SmartEDA, 
               ggrepel, scales, lubridate, dplyr, viridis)
```

### 1.2 - Importing Knowledge Graph Data

For the purpose of this exercise, *mc3.json* file will be used. Before getting started, you should have the data set in the **data** sub-folder.

In the code chunk below, `fromJSON()` of **jsonlite** package is used to import *mc3.json* file into R and save the output object

```{r}

MC3 <- fromJSON("data/MC3_graph.json")
MC3_schema <- fromJSON("data/MC3_schema.json")
```

### 1.3 - **Data Overview**

The dataset was provided by VAST Challenge for MC3. This report utilizes two core datasets: MC3_graph.json, which encodes the knowledge graph of communications, events, and relationships; and MC3_schema.json, which defines the structure, subtypes, and attributes of each node and edge type within the graph. There ngraph contains a total of 1159 nodes and 3226 edges. Full description of node attributes and edge attributes is shown below.

**Nodes Attributes** are as such:

![Node Subtypes](Images/Node%20Attributes.png){fig-align="center" width="600"}

**Edge Attributes** are as such:

![Node-Edge-Node Matrix](Images/Edge%20Attributes.png){fig-align="center" width="594"}

### 1.4 - **Inspecting knowledge graph structure**

Before preparing the data, it is always a good practice to examine the structure of *mc3* knowledge graph.

In the code chunk below `glimpse()` is used to reveal the structure of *mc3* knowledge graph.

```{r}

glimpse(MC3)
```

::: callout-warning
Notice that¬†*Industry*¬†field is in list data type. In general, this data type is not acceptable by¬†`tbl_graph()`¬†of¬†**tidygraph**. In order to avoid error arise when building tidygraph object, it is wiser to exclude this field from the edges data table. However, it might be still useful in subsequent analysis.
:::

### 1.5 - Extract the edges and nodes tables

Next,¬†`as_tibble()`¬†of¬†**tibble**¬†package package is used to extract the nodes and links tibble data frames from¬†*mc3*¬†tibble dataframe into two separate tibble dataframes called¬†*mc3_nodes*¬†and¬†*mc3_edges*¬†respectively.

```{r}

mc3_nodes <- as_tibble(MC3$nodes)
mc3_edges <- as_tibble(MC3$edges)
```

### 1.6 - Brief Analyis of the extracted edges and nodes data (visuals)

It is time for us to apply appropriate EDA methods to examine the data.

**Nodes:**

:::: panel-tabset
In the code chunk below, `ExpCatViz()` of SmartEDA package is used to reveal the frequency distribution of all categorical fields in *mc3_nodes* tibble dataframe.

### The Code Chunk

```{r, echo=TRUE, eval=FALSE}

ExpCatViz(data=mc3_nodes,
          col="lightblue")
```

### The Plots

```{r}

ExpCatViz(data=mc3_nodes,
          col="lightblue")
```

::: callout-note
What useful discovery can you obtained from the visualisation above?
:::
::::

**Edges:**

:::: panel-tabset
On the other hands, code chunk below uses¬†`ExpCATViz()`¬†of SmartEDA package to reveal the frequency distribution of all categorical fields in¬†*mc3_edges*¬†tibble dataframe.

### The Code Chunk

```{r, echo=TRUE, eval=FALSE}

ExpCatViz(data=mc3_edges,
          col="lightblue")
```

### The Plots

```{r, echo=FALSE}

ExpCatViz(data=mc3_edges,
          col="lightblue")
```

::: callout-note
What useful discovery can you obtained from the visualisation above?
:::
::::

## 2 - **Data Cleaning and Wrangling**

### **2.1 - Cleaning and wrangling nodes**

Code chunk below performs the following data cleaning tasks:

-   convert values in id field into character data type,
-   exclude records with `id` value are na,
-   exclude records with similar id values,
-   exclude `thing_collected` field, and
-   save the cleaned tibble dataframe into a new tibble datatable called `mc3_nodes_cleaned`.

```{r}
#| code-fold: true

mc3_nodes_cleaned <- mc3_nodes %>%
  mutate(id = as.character(id)) %>%
  filter(!is.na(id)) %>%
  distinct(id, .keep_all = TRUE) %>%
  select(-thing_collected)
```

### **2.2 - Cleaning and wrangling edges**

Next, the code chunk below will be used to:

-   rename source and target fields to from_id and to_id respectively,
-   convert values in from_id and to_id fields to character data type,
-   exclude values in from_id and to_id which not found in the id field of mc3_nodes_cleaned,
-   exclude records whereby from_id and/or to_id values are missing, and
-   save the cleaned tibble dataframe and called it mc3_edges_cleaned.

```{r}
#| code-fold: true

mc3_edges_cleaned <- mc3_edges %>%
  rename(from_id = source, 
         to_id = target) %>%
  mutate(across(c(from_id, to_id), 
                as.character)) %>%
  filter(from_id %in% mc3_nodes_cleaned$id, 
         to_id %in% mc3_nodes_cleaned$id) %>%
  filter(!is.na(from_id), !is.na(to_id))
```

Next, code chunk below will be used to create mapping of character id in¬†`mc3_nodes_cleaned`¬†to row index.

```{r}
#| code-fold: true

node_index_lookup <- mc3_nodes_cleaned %>%
  mutate(.row_id = row_number()) %>%
  select(id, .row_id)
```

Next, the code chunk below will be used to join and convert¬†`from_id`¬†and¬†`to_id`¬†to integer indices. At the same time we also drop rows with unmatched nodes.

```{r}
#| code-fold: true

mc3_edges_indexed <- mc3_edges_cleaned %>%
  left_join(node_index_lookup, 
            by = c("from_id" = "id")) %>%
  rename(from = .row_id) %>%
  left_join(node_index_lookup, 
            by = c("to_id" = "id")) %>%
  rename(to = .row_id) %>%
  select(from, to, is_inferred, type) %>%
  filter(!is.na(from) & !is.na(to))  
```

Next the code chunk below is used to subset nodes to only those referenced by edges.

```{r}
#| code-fold: true

used_node_indices <- sort(
  unique(c(mc3_edges_indexed$from, 
           mc3_edges_indexed$to)))

mc3_nodes_final <- mc3_nodes_cleaned %>%
  slice(used_node_indices) %>%
  mutate(new_index = row_number())
```

We will then use the code chunk below to rebuild lookup from old index to new index.

```{r}
#| code-fold: true

old_to_new_index <- tibble(
  old_index = used_node_indices,
  new_index = seq_along(
    used_node_indices))
```

Lastly, the code chunk below will be used to update edge indices to match new node table.

```{r}
#| code-fold: true

mc3_edges_final <- mc3_edges_indexed %>%
  left_join(old_to_new_index, 
            by = c("from" = "old_index")) %>%
  rename(from_new = new_index) %>%
  left_join(old_to_new_index, 
            by = c("to" = "old_index")) %>%
  rename(to_new = new_index) %>%
  select(from = from_new, to = to_new, 
         is_inferred, type)
```

### **2.3 - Building the tidygraph object**

Now we are ready to build the tidygraph object by using the code chunk below.

```{r}

mc3_graph <- tbl_graph(
  nodes = mc3_nodes_final,
  edges = mc3_edges_final,
  directed = TRUE
)
```

After the tidygraph object is created, it is always a good practice to examine the object by using¬†`str()`.

```{r}

str(mc3_graph)
```

## 3 - **Exploratory Data Analysis (after cleaning & wrangling)**

Several of the¬†**ggraph**¬†layouts involve randomisation. In order to ensure reproducibility, it is necessary to set the seed value before plotting by using the code chunk below.

```{r}
set.seed(1818)
```

### **3.1 - Visualising the knowledge graph**

Shows how many nodes are of type `Entity`, `Event`, or `Relationship`.

```{r}
#| code-fold: true

mc3_nodes_final %>%
  count(type, sort = TRUE) %>%
  ggplot(aes(x = reorder(type, -n), y = n, fill = type)) +
  geom_col() +
  geom_text(aes(label = n), vjust = -0.3) +
  labs(title = "Node Type Distribution", x = "Type", y = "Count") +
  theme_minimal() +
  theme(legend.position = "none")
```

In the code chunk below,¬†**ggraph**¬†functions are used to create the whole graph.

```{r}
#| code-fold: true

ggraph(mc3_graph, 
       layout = "fr") +
  geom_edge_link(alpha = 0.3, 
                 colour = "gray") +
  geom_node_point(aes(color = `type`), 
                  size = 4) +
  geom_node_text(aes(label = type), 
                 repel = TRUE, 
                 size = 2.5) +
  theme_void()
```

### **3.2 - Entity Sub_type Distribution**

Focuses on what kinds of actors are in the graph ‚Äî Person, Vessel, Organization, etc.

```{r}
#| code-fold: true

mc3_nodes_final %>%
  filter(type == "Entity") %>%
  count(sub_type, sort = TRUE) %>%
  ggplot(aes(x = reorder(sub_type, n), y = n, fill = sub_type)) +
  geom_col() +
  coord_flip() +
  geom_text(aes(label = n), hjust = -0.1) +
  labs(title = "Entity Sub-type Distribution", x = "Sub-type", y = "Count") +
  theme_minimal() +
  theme(legend.position = "none")
```

### **3.3 - Event Sub_type Distribution**

To understand what kinds of actions dominate ‚Äî Communication, Monitoring, Assessment, etc.

```{r}
#| code-fold: true

mc3_nodes_final %>%
  filter(type == "Event") %>%
  count(sub_type, sort = TRUE) %>%
  ggplot(aes(x = reorder(sub_type, n), y = n, fill = sub_type)) +
  geom_col() +
  coord_flip() +
  geom_text(aes(label = n), hjust = -0.1) +
  labs(title = "Event Sub-type Distribution", x = "Sub-type", y = "Count") +
  theme_minimal() +
  theme(legend.position = "none")

```

### **3.4a - List of Communication Participants**

This finds all Entities that **sent or received** communication events ‚Äî i.e., actors who participated in messaging.

```{r}
#| code-fold: true

library(DT)

# Step 1: Get all Communication Event IDs
comm_event_ids <- mc3_nodes_cleaned %>%
  filter(type == "Event", sub_type == "Communication") %>%
  pull(id)

# Step 2: Extract 'sent' edges for communication events
comm_sent_edges <- mc3_edges_cleaned %>%
  filter(type == "sent", to_id %in% comm_event_ids) %>%
  select(comm_id = to_id, sender_id = from_id)

# Step 3: Extract 'received' edges for same communication events
comm_received_edges <- mc3_edges_cleaned %>%
  filter(type == "received", from_id %in% comm_event_ids) %>%
  select(comm_id = from_id, receiver_id = to_id)

# Step 4: Join sent and received edges by communication ID
comm_pairs <- comm_sent_edges %>%
  inner_join(comm_received_edges, by = "comm_id")

# Step 5: Add sender and receiver labels
participants_named <- comm_pairs %>%
  left_join(mc3_nodes_cleaned %>% select(id, sender_label = label), by = c("sender_id" = "id")) %>%
  left_join(mc3_nodes_cleaned %>% select(id, receiver_label = label), by = c("receiver_id" = "id"))



# Step7: Interactive summary of top sender‚Äìreceiver pairs
participants_named %>%
  count(sender_label, receiver_label, sort = TRUE) %>%
  datatable(
    caption = "Top Communication Pairs (Sender ‚Üí Receiver)",
    colnames = c("Sender", "Receiver", "Message Count"),
    options = list(pageLength = 10, autoWidth = TRUE),
    rownames = FALSE
  )

```

### **3.4b - Network Visual of Communication Participants**

This code creates an **interactive communication network graph** using `visNetwork`, where:

-   Each **node** represents a person or entity, **node size** is based on total messages **sent** by that participant.
-   Each **edge (arrow)** represents a communication sent from one participant to another, the thicker the edge, the more message sent to that particular receiver.
-   The layout places **larger (more active) nodes toward the center** in a circular arrangement.

::: panel-tabset
## Ver 1: Layout_in_circle

```{r, fig.width=8, fig.height=14}
#| code-fold: true

library(visNetwork)

# Step 1: Summarize communication edges
comm_edges_vis <- participants_named %>%
  count(sender_id, receiver_id, sort = TRUE) %>%
  rename(from = sender_id, to = receiver_id, value = n)

# Step 2: Compute messages sent per node
message_counts <- comm_edges_vis %>%
  group_by(from) %>%
  summarise(sent_count = sum(value), .groups = "drop")

# Step 3: Prepare nodes, merge with message count and sort
nodes_vis <- mc3_nodes_cleaned %>%
  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %>%
  select(id, label, sub_type) %>%
  left_join(message_counts, by = c("id" = "from")) %>%
  mutate(
    sent_count = replace_na(sent_count, 0),
    size = rescale(sent_count, to = c(10, 40)),  # larger = more active
    title = paste0(label, "<br>Sub-type: ", sub_type,
                   ifelse(!is.na(sent_count), paste0("<br>Sent: ", sent_count, " messages"), ""))
  ) %>%
  arrange(desc(size))  # Important: bigger nodes rendered first = inner in circle layout

# Step 4: Format visNetwork edges
edges_vis <- comm_edges_vis %>%
  mutate(
    arrows = "to",
    width = rescale(value, to = c(1, 6)),
    title = paste("Messages:", value)
  )

# Step 5: Render network with layout_in_circle
visNetwork(nodes_vis, edges_vis, width = "100%", height = "1000px") %>%
  visNodes(size = nodes_vis$size) %>%
  visEdges(smooth = FALSE) %>%
  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %>%
  visIgraphLayout(layout = "layout_in_circle") %>%
  visPhysics(enabled = FALSE) %>%
  visLayout(randomSeed = 1818)

```

## Ver 2: Layout_on_sphere

```{r}
#| code-fold: true
library(visNetwork)

# Step 1: Summarize communication edges
comm_edges_vis <- participants_named %>%
  count(sender_id, receiver_id, sort = TRUE) %>%
  rename(from = sender_id, to = receiver_id, value = n)

# Step 2: Compute messages sent per person (by sender)
message_counts <- comm_edges_vis %>%
  group_by(from) %>%
  summarise(sent_count = sum(value), .groups = "drop")

# Step 3: Prepare nodes with label, subtype, and scaled size
nodes_vis <- mc3_nodes_cleaned %>%
  filter(id %in% unique(c(comm_edges_vis$from, comm_edges_vis$to))) %>%
  select(id, label, sub_type) %>%
  left_join(message_counts, by = c("id" = "from")) %>%
  mutate(
    size = if_else(
      sub_type == "Person",
      rescale(sent_count, to = c(10, 40), na.rm = TRUE),
      15  # default size for other node types
    ),
    title = paste0(label, "<br>Sub-type: ", sub_type,
                   ifelse(!is.na(sent_count), paste0("<br>Sent: ", sent_count, " messages"), ""))
  )

# Step 4: Format edges
edges_vis <- comm_edges_vis %>%
  mutate(
    arrows = "to",
    width = rescale(value, to = c(1, 6)),
    title = paste("Messages:", value)
  )

# Step 5: Render the network with layout_on_sphere
visNetwork(nodes_vis, edges_vis, width = "100%", height = "900px") %>%
  visNodes(size = nodes_vis$size) %>%
  visEdges(smooth = FALSE) %>%
  visOptions(highlightNearest = TRUE, nodesIdSelection = TRUE) %>%
  visIgraphLayout(layout = "layout_on_sphere") %>%
  visPhysics(enabled = FALSE) %>%
  visLayout(randomSeed = 42)


```
:::

## 4 - Task 1: Daily Temporal Patterns in Communication üéØ

**Objective**

1.  Identify **when** communications happen most often during each day.
2.  Detect **shifts in these patterns** over the 2-week period.
3.  Later: Focus on a **specific entity** (e.g., Nadia Conti) and explore **who influences them**.

### Step 1: Extract & Parse Communication Event Timestamps

Extract the Communication Timestamps from `mc3_nodes_final` and filter for communication events.

```{r}

# Filter for Communication events
comm_events <- mc3_nodes_final %>%
  filter(type == "Event", sub_type == "Communication") %>%
  mutate(timestamp = ymd_hms(timestamp)) %>%
  filter(!is.na(timestamp)) %>%
  mutate(
    day = as.Date(timestamp),
    hour = hour(timestamp)
  )
```

Parse the Communication Timestamp into the format "dd/mm/yyy (ddd)" for ease of reference.

```{r}

# Communication events with parsed date and time
comm_events <- mc3_nodes_final %>%
  filter(type == "Event", sub_type == "Communication") %>%
  mutate(timestamp = ymd_hms(timestamp)) %>%
  filter(!is.na(timestamp)) %>%
  mutate(
    hour = hour(timestamp),
    date_label = format(timestamp, "%d/%m/%Y (%a)")  # e.g., "19/03/2040 (Tue)"
  )

```

### Step 2: Visualize the Communication Volume for Analysis

#### **4.1 - Bar Plot of daily communication volume over the 2 weeks period:**

```{r}
#| code-fold: true

# Step 1: Prepare daily message volume data
daily_message_volume <- mc3_nodes_final %>%
  filter(type == "Event", sub_type == "Communication") %>%
  mutate(
    timestamp = ymd_hms(timestamp),
    date = as.Date(timestamp),
    date_label = format(timestamp, "%d/%m/%Y (%a)")
  ) %>%
  group_by(date, date_label) %>%
  summarise(message_count = n(), .groups = "drop") %>%
  arrange(date)

# Step 2: Compute average and total message count
avg_msg_count <- mean(daily_message_volume$message_count)
total_msg_count <- sum(daily_message_volume$message_count)

# Step 3: Plot bar chart with average + total labels
ggplot(daily_message_volume, aes(x = date_label, y = message_count)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_text(
    aes(label = message_count),
    vjust = -0.3,
    size = 2.5,
    color = "grey40"
  ) +
  geom_hline(yintercept = avg_msg_count, color = "red", linetype = "dashed", size = 1.2) +
  annotate(
    "label", x = 1, y = avg_msg_count + 2,
    label = paste("Average =", round(avg_msg_count, 1)),
    color = "red", fill = "grey90",
    label.size = 0, hjust = -0.2, vjust = 3
  ) +
  annotate(
    "label", x = nrow(daily_message_volume), y = max(daily_message_volume$message_count) + 5,
    label = paste("Total =", total_msg_count),
    color = "black", fill = "lightgrey",
    label.size = 0.3, hjust = 1.1, vjust = 1
  ) +
  labs(
    title = "Daily Radio Communication Volume",
    x = "Date",
    y = "Message Count"
  ) +
  theme_minimal(base_size = 11) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(face = "bold")
  )

```

#### **4.2 - Interactive Table of daily communication volume variation(message count)**

```{r}
#| code-fold: true
library(DT)

# Daily message volume with comparisons
daily_message_volume <- mc3_nodes_final %>%
  filter(type == "Event", sub_type == "Communication") %>%
  mutate(
    timestamp = ymd_hms(timestamp),
    date = as.Date(timestamp),
    date_label = format(timestamp, "%d/%m/%Y (%a)")
  ) %>%
  group_by(date, date_label) %>%
  summarise(message_count = n(), .groups = "drop") %>%
  arrange(date) %>%
  mutate(
    change_from_prev = message_count - lag(message_count),
    pct_change_from_prev = round((message_count - lag(message_count)) / lag(message_count) * 100, 2)
  )

datatable(
  daily_message_volume %>% select(-date),  # remove raw date if not needed
  caption = "Daily Message Volume with Day-over-Day Change",
  options = list(pageLength = 14, order = list(list(0, 'asc'))),
  rownames = FALSE
)

```

#### **4.3a - Heat Map of hourly message volume for each day over the 2 weeks period:**

This heat map is interactive and you may choose to hover on the tile to display the **date, time, and message count**

```{r}
#| code-fold: true

library(forcats)
library(plotly)

# Step 1: Reconstruct sender‚Äìreceiver‚Äìtimestamp structure
comm_events_raw <- mc3_nodes_final %>%
  filter(type == "Event", sub_type == "Communication") %>%
  select(event_id = id, timestamp) %>%
  mutate(timestamp = ymd_hms(timestamp),
         hour = hour(timestamp),
         date_label = format(timestamp, "%d/%m/%Y (%a)"))

# Step 2: Get sender (sent) and receiver (received) links
comm_edges_sent <- mc3_edges_cleaned %>%
  filter(type == "sent") %>%
  select(event_id = to_id, sender_id = from_id)

comm_edges_recv <- mc3_edges_cleaned %>%
  filter(type == "received") %>%
  select(event_id = from_id, receiver_id = to_id)

# Step 3: Join all together into sender‚Äìreceiver‚Äìtimestamp
comm_links <- comm_events_raw %>%
  left_join(comm_edges_sent, by = "event_id") %>%
  left_join(comm_edges_recv, by = "event_id") %>%
  left_join(mc3_nodes_cleaned %>% select(sender_id = id, sender_label = label), by = "sender_id") %>%
  left_join(mc3_nodes_cleaned %>% select(receiver_id = id, receiver_label = label), by = "receiver_id")

# Step 4: Aggregate total messages per hour/day
comm_heatmap <- comm_links %>%
  group_by(date_label, hour) %>%
  summarise(
    count = n(),
    top_sender = names(sort(table(sender_label), decreasing = TRUE))[1],
    sender_count = max(table(sender_label)),
    top_receiver = names(sort(table(receiver_label), decreasing = TRUE))[1],
    receiver_count = max(table(receiver_label)),
    .groups = "drop"
  ) %>%
  mutate(
    tooltip = paste0(
      "üìÖ Date: ", date_label,
      "<br>‚è∞ Hour: ", sprintf("%02d:00", hour),
      "<br>üì® Messages: ", count,
      "<br>üî¥ Top Sender: ", top_sender, " (", sender_count, ")",
      "<br>üü¢ Top Receiver: ", top_receiver, " (", receiver_count, ")"
    )
  )

# Step 5: Static ggplot
p <- ggplot(comm_heatmap, aes(
  x = hour,
  y = fct_rev(factor(date_label)),
  fill = count,
  text = tooltip
)) +
  geom_tile(color = "white") +
  scale_fill_viridis_c(option = "inferno", direction = -1, name = "Message Count") +
  scale_x_continuous(
    breaks = 0:23,
    labels = function(x) sprintf("%02d:00", x)
  ) +
  labs(
    title = "Hourly Heatmap of Radio Communications by Day",
    x = "Hour of Day",
    y = NULL
  ) +
  theme_minimal(base_size = 10) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid = element_blank()
  )

# Step 6: Make interactive
ggplotly(p, tooltip = "text")

```

We will increase the resolution to half-hour time slots.

#### **4.4b - Heat Map of half-hourly message volume for each day over the 2 weeks period:**

This heat map is interactive and you may choose to hover on the tile to display the **date, time, and message count**.

```{r}
#| code-fold: true

library(forcats)
library(plotly)

# Step 1: Fix sender and receiver edges
comm_edges_sent <- mc3_edges_cleaned %>%
  filter(type == "sent") %>%
  select(event_id = to_id, sender_id = from_id)

comm_edges_recv <- mc3_edges_cleaned %>%
  filter(type == "received") %>%
  select(event_id = from_id, receiver_id = to_id)  # ‚úÖ fixed receiver_id

# Step 2: Reconstruct sender‚Äìreceiver‚Äìevent linkage
comm_events_raw <- mc3_nodes_final %>%
  filter(type == "Event", sub_type == "Communication") %>%
  select(event_id = id, timestamp) %>%
  mutate(
    timestamp = ymd_hms(timestamp),
    hour = hour(timestamp),
    minute = minute(timestamp),
    time_bin = hour + ifelse(minute < 30, 0, 0.5),
    date_label = format(timestamp, "%d/%m/%Y (%a)"),
    time_label = sprintf("%02d:%02d", floor(time_bin), ifelse(time_bin %% 1 == 0, 0, 30))
  )

# Step 3: Join to get sender/receiver labels
comm_links <- comm_events_raw %>%
  left_join(comm_edges_sent, by = "event_id") %>%
  left_join(comm_edges_recv, by = "event_id") %>%
  left_join(mc3_nodes_cleaned %>% select(id, sender_label = label), by = c("sender_id" = "id")) %>%
  left_join(mc3_nodes_cleaned %>% select(id, receiver_label = label), by = c("receiver_id" = "id"))

# Step 4: Aggregate by half-hour + label top actors
comm_heatmap <- comm_links %>%
  group_by(date_label, time_bin, time_label) %>%
  summarise(
    count = n(),
    top_sender = names(sort(table(sender_label), decreasing = TRUE))[1],
    sender_count = max(table(sender_label)),
    top_receiver = names(sort(table(receiver_label), decreasing = TRUE))[1],
    receiver_count = max(table(receiver_label)),
    .groups = "drop"
  ) %>%
  mutate(
    tooltip = paste0(
      "üìÖ Date: ", date_label,
      "<br>üïí Time: ", time_label,
      "<br>üì® Messages: ", count,
      "<br>üî¥ Top Sender: ", top_sender, " (", sender_count, ")",
      "<br>üü¢ Top Receiver: ", top_receiver, " (", receiver_count, ")"
    )
  )

# Step 5: ggplot
p <- ggplot(comm_heatmap, aes(x = time_bin, y = fct_rev(factor(date_label)), fill = count, text = tooltip)) +
  geom_tile(color = "white") +
  scale_fill_viridis_c(
    option = "inferno",
    direction = -1,
    name = "Message Count"
  ) +
  scale_x_continuous(
    breaks = seq(0, 23.5, by = 0.5),
    labels = function(x) sprintf("%02d:%02d", floor(x), ifelse(x %% 1 == 0, 0, 30))
  ) +
  labs(
    title = "Half-Hourly Heatmap of Radio Communications by Day",
    x = "Time of Day",
    y = NULL
  ) +
  theme_minimal(base_size = 10) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid = element_blank()
  )

# Step 6: Convert to interactive Plotly plot
ggplotly(p, tooltip = "text")
```

#### **4.4c - Density plot of Daily half-hourly message volume over the 2 weeks period:**

The faceted density plot that shows the **distribution of communication events by time of day**, broken down for each day in the dataset. It helps to visually detect **temporal communication patterns**, intensity, and consistency over multiple days.

::: panel-tabset
### Overview of the 2 week period

```{r}
#| code-fold: true
# Step 1: Preprocess communication events
comm_events <- mc3_nodes_final %>%
  filter(type == "Event", sub_type == "Communication") %>%
  mutate(timestamp = ymd_hms(timestamp)) %>%
  filter(!is.na(timestamp)) %>%
  mutate(
    date_label = format(timestamp, "%d/%m/%Y (%a)"),
    hour = hour(timestamp),
    minute = minute(timestamp),
    time_bin = hour + ifelse(minute < 30, 0, 0.5)
  )

# Step 2: Summarise daily medians and counts
daily_stats <- comm_events %>%
  group_by(date_label) %>%
  summarise(
    median_time = median(time_bin),
    msg_count = n(),
    .groups = "drop"
  )

# Step 3: Plot
ggplot(comm_events, aes(x = time_bin)) +
  geom_density(fill = "steelblue", alpha = 0.7) +
  geom_vline(data = daily_stats, aes(xintercept = median_time),
             color = "red", linetype = "dashed", linewidth = 0.6) +
  geom_text(
    data = daily_stats,
    aes(x = 20.5, y = 0.25, label = paste("Total:", msg_count)),
    inherit.aes = FALSE,
    size = 3,
    color = "grey20",
    hjust = 1
  ) +
  facet_wrap(~ date_label, ncol = 4) +
  scale_x_continuous(
    breaks = seq(0, 23.5, by = 0.5),
    labels = NULL  # suppress all x-axis labels
  ) +
  labs(
    title = "Daily Communication Patterns (Half-Hourly)",
    x = "Time of Day",
    y = "Density"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(face = "bold"),
    panel.grid.minor = element_blank()
  )

```

### Day 1 - 01/10/2040

```{r}
#| code-fold: true

# Filter for selected date
daily_data <- filter(comm_events, date_label == "01/10/2040 (Mon)")

# Build density data to find full curve
density_data <- ggplot_build(
  ggplot(daily_data, aes(x = time_bin)) +
    geom_density()
)$data[[1]]

# Identify peaks within ¬±10% of the maximum density
max_y <- max(density_data$y)
peak_threshold <- 0.9 * max_y

major_peaks <- density_data %>%
  filter(y >= peak_threshold) %>%
  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins
  summarise(
    peak_time = x[which.max(y)],
    peak_density = max(y),
    .groups = "drop"
  ) %>%
  mutate(
    label = sprintf("Peak: %02d:%02d",
                    floor(peak_time),
                    ifelse(peak_time %% 1 == 0, 0, 30))
  )

# Message count
msg_count <- nrow(daily_data)

# Final plot
ggplot(daily_data, aes(x = time_bin)) +
  geom_density(fill = "steelblue", alpha = 0.7) +
  geom_vline(data = major_peaks, aes(xintercept = peak_time),
             color = "red", linetype = "dashed", linewidth = 0.6) +
  geom_text(data = major_peaks,
            aes(x = peak_time, y = 0.23, label = label),
            color = "red", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +
  annotate("text", x = 20.5, y = 0.25,
           label = paste("Total messages communicated:", msg_count),
           hjust = 1, size = 4, color = "grey30") +
  labs(
    title = "Half-Hourly Communication Density (Multiple Peaks Highlighted)",
    x = "Time of Day",
    y = "Density"
  ) +
  scale_x_continuous(
    breaks = seq(0, 23.5, by = 0.5),
    labels = function(x) sprintf("%02d:%02d", floor(x), ifelse(x %% 1 == 0, 0, 30))
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(face = "bold")
  )

```

### Day 2 - 02/10/2040

```{r}
#| code-fold: true

# Filter for selected date
daily_data <- filter(comm_events, date_label == "02/10/2040 (Tue)")

# Build density data to find full curve
density_data <- ggplot_build(
  ggplot(daily_data, aes(x = time_bin)) +
    geom_density()
)$data[[1]]

# Identify peaks within ¬±10% of the maximum density
max_y <- max(density_data$y)
peak_threshold <- 0.9 * max_y

major_peaks <- density_data %>%
  filter(y >= peak_threshold) %>%
  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins
  summarise(
    peak_time = x[which.max(y)],
    peak_density = max(y),
    .groups = "drop"
  ) %>%
  mutate(
    label = sprintf("Peak: %02d:%02d",
                    floor(peak_time),
                    ifelse(peak_time %% 1 == 0, 0, 30))
  )

# Message count
msg_count <- nrow(daily_data)

# Final plot
ggplot(daily_data, aes(x = time_bin)) +
  geom_density(fill = "steelblue", alpha = 0.7) +
  geom_vline(data = major_peaks, aes(xintercept = peak_time),
             color = "red", linetype = "dashed", linewidth = 0.6) +
  geom_text(data = major_peaks,
            aes(x = peak_time, y = 0.23, label = label),
            color = "red", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +
  annotate("text", x = 20.5, y = 0.25,
           label = paste("Total messages communicated:", msg_count),
           hjust = 1, size = 4, color = "grey30") +
  labs(
    title = "Half-Hourly Communication Density (Multiple Peaks Highlighted)",
    x = "Time of Day",
    y = "Density"
  ) +
  scale_x_continuous(
    breaks = seq(0, 23.5, by = 0.5),
    labels = function(x) sprintf("%02d:%02d", floor(x), ifelse(x %% 1 == 0, 0, 30))
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(face = "bold")
  )

```

### Day 3 - 03/10/2040

```{r}
#| code-fold: true

# Filter for selected date
daily_data <- filter(comm_events, date_label == "03/10/2040 (Wed)")

# Build density data to find full curve
density_data <- ggplot_build(
  ggplot(daily_data, aes(x = time_bin)) +
    geom_density()
)$data[[1]]

# Identify peaks within ¬±10% of the maximum density
max_y <- max(density_data$y)
peak_threshold <- 0.9 * max_y

major_peaks <- density_data %>%
  filter(y >= peak_threshold) %>%
  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins
  summarise(
    peak_time = x[which.max(y)],
    peak_density = max(y),
    .groups = "drop"
  ) %>%
  mutate(
    label = sprintf("Peak: %02d:%02d",
                    floor(peak_time),
                    ifelse(peak_time %% 1 == 0, 0, 30))
  )

# Message count
msg_count <- nrow(daily_data)

# Final plot
ggplot(daily_data, aes(x = time_bin)) +
  geom_density(fill = "steelblue", alpha = 0.7) +
  geom_vline(data = major_peaks, aes(xintercept = peak_time),
             color = "red", linetype = "dashed", linewidth = 0.6) +
  geom_text(data = major_peaks,
            aes(x = peak_time, y = 0.23, label = label),
            color = "red", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +
  annotate("text", x = 20.5, y = 0.25,
           label = paste("Total messages communicated:", msg_count),
           hjust = 1, size = 4, color = "grey30") +
  labs(
    title = "Half-Hourly Communication Density (Multiple Peaks Highlighted)",
    x = "Time of Day",
    y = "Density"
  ) +
  scale_x_continuous(
    breaks = seq(0, 23.5, by = 0.5),
    labels = function(x) sprintf("%02d:%02d", floor(x), ifelse(x %% 1 == 0, 0, 30))
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(face = "bold")
  )

```

### Day 4 - 04/10/2040

```{r}
#| code-fold: true

# Filter for selected date
daily_data <- filter(comm_events, date_label == "04/10/2040 (Thu)")

# Build density data to find full curve
density_data <- ggplot_build(
  ggplot(daily_data, aes(x = time_bin)) +
    geom_density()
)$data[[1]]

# Identify peaks within ¬±10% of the maximum density
max_y <- max(density_data$y)
peak_threshold <- 0.9 * max_y

major_peaks <- density_data %>%
  filter(y >= peak_threshold) %>%
  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins
  summarise(
    peak_time = x[which.max(y)],
    peak_density = max(y),
    .groups = "drop"
  ) %>%
  mutate(
    label = sprintf("Peak: %02d:%02d",
                    floor(peak_time),
                    ifelse(peak_time %% 1 == 0, 0, 30))
  )

# Message count
msg_count <- nrow(daily_data)

# Final plot
ggplot(daily_data, aes(x = time_bin)) +
  geom_density(fill = "steelblue", alpha = 0.7) +
  geom_vline(data = major_peaks, aes(xintercept = peak_time),
             color = "red", linetype = "dashed", linewidth = 0.6) +
  geom_text(data = major_peaks,
            aes(x = peak_time, y = 0.23, label = label),
            color = "red", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +
  annotate("text", x = 20.5, y = 0.25,
           label = paste("Total messages communicated:", msg_count),
           hjust = 1, size = 4, color = "grey30") +
  labs(
    title = "Half-Hourly Communication Density (Multiple Peaks Highlighted)",
    x = "Time of Day",
    y = "Density"
  ) +
  scale_x_continuous(
    breaks = seq(0, 23.5, by = 0.5),
    labels = function(x) sprintf("%02d:%02d", floor(x), ifelse(x %% 1 == 0, 0, 30))
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(face = "bold")
  )

```

### Day 5 - 05/10/2040

```{r}
#| code-fold: true

# Filter for selected date
daily_data <- filter(comm_events, date_label == "05/10/2040 (Fri)")

# Build density data to find full curve
density_data <- ggplot_build(
  ggplot(daily_data, aes(x = time_bin)) +
    geom_density()
)$data[[1]]

# Identify peaks within ¬±10% of the maximum density
max_y <- max(density_data$y)
peak_threshold <- 0.9 * max_y

major_peaks <- density_data %>%
  filter(y >= peak_threshold) %>%
  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins
  summarise(
    peak_time = x[which.max(y)],
    peak_density = max(y),
    .groups = "drop"
  ) %>%
  mutate(
    label = sprintf("Peak: %02d:%02d",
                    floor(peak_time),
                    ifelse(peak_time %% 1 == 0, 0, 30))
  )

# Message count
msg_count <- nrow(daily_data)

# Final plot
ggplot(daily_data, aes(x = time_bin)) +
  geom_density(fill = "steelblue", alpha = 0.7) +
  geom_vline(data = major_peaks, aes(xintercept = peak_time),
             color = "red", linetype = "dashed", linewidth = 0.6) +
  geom_text(data = major_peaks,
            aes(x = peak_time, y = 0.23, label = label),
            color = "red", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +
  annotate("text", x = 20.5, y = 0.25,
           label = paste("Total messages communicated:", msg_count),
           hjust = 1, size = 4, color = "grey30") +
  labs(
    title = "Half-Hourly Communication Density (Multiple Peaks Highlighted)",
    x = "Time of Day",
    y = "Density"
  ) +
  scale_x_continuous(
    breaks = seq(0, 23.5, by = 0.5),
    labels = function(x) sprintf("%02d:%02d", floor(x), ifelse(x %% 1 == 0, 0, 30))
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(face = "bold")
  )

```

### Day 6 - 06/10/2040

```{r}
#| code-fold: true

# Filter for selected date
daily_data <- filter(comm_events, date_label == "06/10/2040 (Sat)")

# Build density data to find full curve
density_data <- ggplot_build(
  ggplot(daily_data, aes(x = time_bin)) +
    geom_density()
)$data[[1]]

# Identify peaks within ¬±10% of the maximum density
max_y <- max(density_data$y)
peak_threshold <- 0.9 * max_y

major_peaks <- density_data %>%
  filter(y >= peak_threshold) %>%
  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins
  summarise(
    peak_time = x[which.max(y)],
    peak_density = max(y),
    .groups = "drop"
  ) %>%
  mutate(
    label = sprintf("Peak: %02d:%02d",
                    floor(peak_time),
                    ifelse(peak_time %% 1 == 0, 0, 30))
  )

# Message count
msg_count <- nrow(daily_data)

# Final plot
ggplot(daily_data, aes(x = time_bin)) +
  geom_density(fill = "steelblue", alpha = 0.7) +
  geom_vline(data = major_peaks, aes(xintercept = peak_time),
             color = "red", linetype = "dashed", linewidth = 0.6) +
  geom_text(data = major_peaks,
            aes(x = peak_time, y = 0.23, label = label),
            color = "red", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +
  annotate("text", x = 20.5, y = 0.25,
           label = paste("Total messages communicated:", msg_count),
           hjust = 1, size = 4, color = "grey30") +
  labs(
    title = "Half-Hourly Communication Density (Multiple Peaks Highlighted)",
    x = "Time of Day",
    y = "Density"
  ) +
  scale_x_continuous(
    breaks = seq(0, 23.5, by = 0.5),
    labels = function(x) sprintf("%02d:%02d", floor(x), ifelse(x %% 1 == 0, 0, 30))
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(face = "bold")
  )

```

### Day 7 - 07/10/2040

```{r}
#| code-fold: true

# Filter for selected date
daily_data <- filter(comm_events, date_label == "07/10/2040 (Sun)")

# Build density data to find full curve
density_data <- ggplot_build(
  ggplot(daily_data, aes(x = time_bin)) +
    geom_density()
)$data[[1]]

# Identify peaks within ¬±10% of the maximum density
max_y <- max(density_data$y)
peak_threshold <- 0.9 * max_y

major_peaks <- density_data %>%
  filter(y >= peak_threshold) %>%
  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins
  summarise(
    peak_time = x[which.max(y)],
    peak_density = max(y),
    .groups = "drop"
  ) %>%
  mutate(
    label = sprintf("Peak: %02d:%02d",
                    floor(peak_time),
                    ifelse(peak_time %% 1 == 0, 0, 30))
  )

# Message count
msg_count <- nrow(daily_data)

# Final plot
ggplot(daily_data, aes(x = time_bin)) +
  geom_density(fill = "steelblue", alpha = 0.7) +
  geom_vline(data = major_peaks, aes(xintercept = peak_time),
             color = "red", linetype = "dashed", linewidth = 0.6) +
  geom_text(data = major_peaks,
            aes(x = peak_time, y = 0.23, label = label),
            color = "red", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +
  annotate("text", x = 20.5, y = 0.25,
           label = paste("Total messages communicated:", msg_count),
           hjust = 1, size = 4, color = "grey30") +
  labs(
    title = "Half-Hourly Communication Density (Multiple Peaks Highlighted)",
    x = "Time of Day",
    y = "Density"
  ) +
  scale_x_continuous(
    breaks = seq(0, 23.5, by = 0.5),
    labels = function(x) sprintf("%02d:%02d", floor(x), ifelse(x %% 1 == 0, 0, 30))
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(face = "bold")
  )

```

### Day 8 - 08/10/2040

```{r}
#| code-fold: true

# Filter for selected date
daily_data <- filter(comm_events, date_label == "08/10/2040 (Mon)")

# Build density data to find full curve
density_data <- ggplot_build(
  ggplot(daily_data, aes(x = time_bin)) +
    geom_density()
)$data[[1]]

# Identify peaks within ¬±10% of the maximum density
max_y <- max(density_data$y)
peak_threshold <- 0.9 * max_y

major_peaks <- density_data %>%
  filter(y >= peak_threshold) %>%
  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins
  summarise(
    peak_time = x[which.max(y)],
    peak_density = max(y),
    .groups = "drop"
  ) %>%
  mutate(
    label = sprintf("Peak: %02d:%02d",
                    floor(peak_time),
                    ifelse(peak_time %% 1 == 0, 0, 30))
  )

# Message count
msg_count <- nrow(daily_data)

# Final plot
ggplot(daily_data, aes(x = time_bin)) +
  geom_density(fill = "steelblue", alpha = 0.7) +
  geom_vline(data = major_peaks, aes(xintercept = peak_time),
             color = "red", linetype = "dashed", linewidth = 0.6) +
  geom_text(data = major_peaks,
            aes(x = peak_time, y = 0.23, label = label),
            color = "red", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +
  annotate("text", x = 20.5, y = 0.25,
           label = paste("Total messages communicated:", msg_count),
           hjust = 1, size = 4, color = "grey30") +
  labs(
    title = "Half-Hourly Communication Density (Multiple Peaks Highlighted)",
    x = "Time of Day",
    y = "Density"
  ) +
  scale_x_continuous(
    breaks = seq(0, 23.5, by = 0.5),
    labels = function(x) sprintf("%02d:%02d", floor(x), ifelse(x %% 1 == 0, 0, 30))
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(face = "bold")
  )

```

### Day 9 - 09/10/2040

```{r}
#| code-fold: true

# Filter for selected date
daily_data <- filter(comm_events, date_label == "09/10/2040 (Tue)")

# Build density data to find full curve
density_data <- ggplot_build(
  ggplot(daily_data, aes(x = time_bin)) +
    geom_density()
)$data[[1]]

# Identify peaks within ¬±10% of the maximum density
max_y <- max(density_data$y)
peak_threshold <- 0.9 * max_y

major_peaks <- density_data %>%
  filter(y >= peak_threshold) %>%
  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins
  summarise(
    peak_time = x[which.max(y)],
    peak_density = max(y),
    .groups = "drop"
  ) %>%
  mutate(
    label = sprintf("Peak: %02d:%02d",
                    floor(peak_time),
                    ifelse(peak_time %% 1 == 0, 0, 30))
  )

# Message count
msg_count <- nrow(daily_data)

# Final plot
ggplot(daily_data, aes(x = time_bin)) +
  geom_density(fill = "steelblue", alpha = 0.7) +
  geom_vline(data = major_peaks, aes(xintercept = peak_time),
             color = "red", linetype = "dashed", linewidth = 0.6) +
  geom_text(data = major_peaks,
            aes(x = peak_time, y = 0.23, label = label),
            color = "red", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +
  annotate("text", x = 20.5, y = 0.25,
           label = paste("Total messages communicated:", msg_count),
           hjust = 1, size = 4, color = "grey30") +
  labs(
    title = "Half-Hourly Communication Density (Multiple Peaks Highlighted)",
    x = "Time of Day",
    y = "Density"
  ) +
  scale_x_continuous(
    breaks = seq(0, 23.5, by = 0.5),
    labels = function(x) sprintf("%02d:%02d", floor(x), ifelse(x %% 1 == 0, 0, 30))
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(face = "bold")
  )

```

### Day 10 - 10/10/2040

```{r}
#| code-fold: true

# Filter for selected date
daily_data <- filter(comm_events, date_label == "10/10/2040 (Wed)")

# Build density data to find full curve
density_data <- ggplot_build(
  ggplot(daily_data, aes(x = time_bin)) +
    geom_density()
)$data[[1]]

# Identify peaks within ¬±10% of the maximum density
max_y <- max(density_data$y)
peak_threshold <- 0.9 * max_y

major_peaks <- density_data %>%
  filter(y >= peak_threshold) %>%
  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins
  summarise(
    peak_time = x[which.max(y)],
    peak_density = max(y),
    .groups = "drop"
  ) %>%
  mutate(
    label = sprintf("Peak: %02d:%02d",
                    floor(peak_time),
                    ifelse(peak_time %% 1 == 0, 0, 30))
  )

# Message count
msg_count <- nrow(daily_data)

# Final plot
ggplot(daily_data, aes(x = time_bin)) +
  geom_density(fill = "steelblue", alpha = 0.7) +
  geom_vline(data = major_peaks, aes(xintercept = peak_time),
             color = "red", linetype = "dashed", linewidth = 0.6) +
  geom_text(data = major_peaks,
            aes(x = peak_time, y = 0.23, label = label),
            color = "red", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +
  annotate("text", x = 20.5, y = 0.25,
           label = paste("Total messages communicated:", msg_count),
           hjust = 1, size = 4, color = "grey30") +
  labs(
    title = "Half-Hourly Communication Density (Multiple Peaks Highlighted)",
    x = "Time of Day",
    y = "Density"
  ) +
  scale_x_continuous(
    breaks = seq(0, 23.5, by = 0.5),
    labels = function(x) sprintf("%02d:%02d", floor(x), ifelse(x %% 1 == 0, 0, 30))
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(face = "bold")
  )

```

### Day 11 - 11/10/2040

```{r}
#| code-fold: true

# Filter for selected date
daily_data <- filter(comm_events, date_label == "11/10/2040 (Thu)")

# Build density data to find full curve
density_data <- ggplot_build(
  ggplot(daily_data, aes(x = time_bin)) +
    geom_density()
)$data[[1]]

# Identify peaks within ¬±10% of the maximum density
max_y <- max(density_data$y)
peak_threshold <- 0.9 * max_y

major_peaks <- density_data %>%
  filter(y >= peak_threshold) %>%
  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins
  summarise(
    peak_time = x[which.max(y)],
    peak_density = max(y),
    .groups = "drop"
  ) %>%
  mutate(
    label = sprintf("Peak: %02d:%02d",
                    floor(peak_time),
                    ifelse(peak_time %% 1 == 0, 0, 30))
  )

# Message count
msg_count <- nrow(daily_data)

# Final plot
ggplot(daily_data, aes(x = time_bin)) +
  geom_density(fill = "steelblue", alpha = 0.7) +
  geom_vline(data = major_peaks, aes(xintercept = peak_time),
             color = "red", linetype = "dashed", linewidth = 0.6) +
  geom_text(data = major_peaks,
            aes(x = peak_time, y = 0.23, label = label),
            color = "red", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +
  annotate("text", x = 20.5, y = 0.25,
           label = paste("Total messages communicated:", msg_count),
           hjust = 1, size = 4, color = "grey30") +
  labs(
    title = "Half-Hourly Communication Density (Multiple Peaks Highlighted)",
    x = "Time of Day",
    y = "Density"
  ) +
  scale_x_continuous(
    breaks = seq(0, 23.5, by = 0.5),
    labels = function(x) sprintf("%02d:%02d", floor(x), ifelse(x %% 1 == 0, 0, 30))
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(face = "bold")
  )

```

### Day 12 - 12/10/2040

```{r}
#| code-fold: true

# Filter for selected date
daily_data <- filter(comm_events, date_label == "12/10/2040 (Fri)")

# Build density data to find full curve
density_data <- ggplot_build(
  ggplot(daily_data, aes(x = time_bin)) +
    geom_density()
)$data[[1]]

# Identify peaks within ¬±10% of the maximum density
max_y <- max(density_data$y)
peak_threshold <- 0.9 * max_y

major_peaks <- density_data %>%
  filter(y >= peak_threshold) %>%
  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins
  summarise(
    peak_time = x[which.max(y)],
    peak_density = max(y),
    .groups = "drop"
  ) %>%
  mutate(
    label = sprintf("Peak: %02d:%02d",
                    floor(peak_time),
                    ifelse(peak_time %% 1 == 0, 0, 30))
  )

# Message count
msg_count <- nrow(daily_data)

# Final plot
ggplot(daily_data, aes(x = time_bin)) +
  geom_density(fill = "steelblue", alpha = 0.7) +
  geom_vline(data = major_peaks, aes(xintercept = peak_time),
             color = "red", linetype = "dashed", linewidth = 0.6) +
  geom_text(data = major_peaks,
            aes(x = peak_time, y = 0.23, label = label),
            color = "red", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +
  annotate("text", x = 20.5, y = 0.25,
           label = paste("Total messages communicated:", msg_count),
           hjust = 1, size = 4, color = "grey30") +
  labs(
    title = "Half-Hourly Communication Density (Multiple Peaks Highlighted)",
    x = "Time of Day",
    y = "Density"
  ) +
  scale_x_continuous(
    breaks = seq(0, 23.5, by = 0.5),
    labels = function(x) sprintf("%02d:%02d", floor(x), ifelse(x %% 1 == 0, 0, 30))
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(face = "bold")
  )

```

### Day 13 - 13/10/2040

```{r}
#| code-fold: true

# Filter for selected date
daily_data <- filter(comm_events, date_label == "13/10/2040 (Sat)")

# Build density data to find full curve
density_data <- ggplot_build(
  ggplot(daily_data, aes(x = time_bin)) +
    geom_density()
)$data[[1]]

# Identify peaks within ¬±10% of the maximum density
max_y <- max(density_data$y)
peak_threshold <- 0.9 * max_y

major_peaks <- density_data %>%
  filter(y >= peak_threshold) %>%
  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins
  summarise(
    peak_time = x[which.max(y)],
    peak_density = max(y),
    .groups = "drop"
  ) %>%
  mutate(
    label = sprintf("Peak: %02d:%02d",
                    floor(peak_time),
                    ifelse(peak_time %% 1 == 0, 0, 30))
  )

# Message count
msg_count <- nrow(daily_data)

# Final plot
ggplot(daily_data, aes(x = time_bin)) +
  geom_density(fill = "steelblue", alpha = 0.7) +
  geom_vline(data = major_peaks, aes(xintercept = peak_time),
             color = "red", linetype = "dashed", linewidth = 0.6) +
  geom_text(data = major_peaks,
            aes(x = peak_time, y = 0.23, label = label),
            color = "red", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +
  annotate("text", x = 20.5, y = 0.25,
           label = paste("Total messages communicated:", msg_count),
           hjust = 1, size = 4, color = "grey30") +
  labs(
    title = "Half-Hourly Communication Density (Multiple Peaks Highlighted)",
    x = "Time of Day",
    y = "Density"
  ) +
  scale_x_continuous(
    breaks = seq(0, 23.5, by = 0.5),
    labels = function(x) sprintf("%02d:%02d", floor(x), ifelse(x %% 1 == 0, 0, 30))
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(face = "bold")
  )

```

### Day 14 - 14/10/2040

```{r}
#| code-fold: true

# Filter for selected date
daily_data <- filter(comm_events, date_label == "14/10/2040 (Sun)")

# Build density data to find full curve
density_data <- ggplot_build(
  ggplot(daily_data, aes(x = time_bin)) +
    geom_density()
)$data[[1]]

# Identify peaks within ¬±10% of the maximum density
max_y <- max(density_data$y)
peak_threshold <- 0.9 * max_y

major_peaks <- density_data %>%
  filter(y >= peak_threshold) %>%
  group_by(grp = cumsum(c(1, diff(x) > 0.5))) %>%  # group close bins
  summarise(
    peak_time = x[which.max(y)],
    peak_density = max(y),
    .groups = "drop"
  ) %>%
  mutate(
    label = sprintf("Peak: %02d:%02d",
                    floor(peak_time),
                    ifelse(peak_time %% 1 == 0, 0, 30))
  )

# Message count
msg_count <- nrow(daily_data)

# Final plot
ggplot(daily_data, aes(x = time_bin)) +
  geom_density(fill = "steelblue", alpha = 0.7) +
  geom_vline(data = major_peaks, aes(xintercept = peak_time),
             color = "red", linetype = "dashed", linewidth = 0.6) +
  geom_text(data = major_peaks,
            aes(x = peak_time, y = 0.23, label = label),
            color = "red", size = 3.5, hjust = -0.1, inherit.aes = FALSE) +
  annotate("text", x = 20.5, y = 0.25,
           label = paste("Total messages communicated:", msg_count),
           hjust = 1, size = 4, color = "grey30") +
  labs(
    title = "Half-Hourly Communication Density (Multiple Peaks Highlighted)",
    x = "Time of Day",
    y = "Density"
  ) +
  scale_x_continuous(
    breaks = seq(0, 23.5, by = 0.5),
    labels = function(x) sprintf("%02d:%02d", floor(x), ifelse(x %% 1 == 0, 0, 30))
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(face = "bold")
  )

```
:::

üìà **Insights This Visualization Offers**

### Step 3: Plot Combined Hourly and Half-hourly Communication Volume

**Bar Plot of combined hourly message volume over the 2 weeks period:**

```{r}
#| code-fold: true

# Prepare data
comm_hourly <- comm_events %>%
  count(hour) %>%
  mutate(
    hour_label = sprintf("%02d:00", hour),  # Format to hh:mm
    percent = n / sum(n)
  )

# Plot
ggplot(comm_hourly, aes(x = hour_label, y = n)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_text_repel(
    aes(label = paste0(n, " (", percent(percent, accuracy = 1), ")")),
    nudge_y = 3,
    size = 2.5,
    direction = "y",
    max.overlaps = Inf
  ) +
  labs(
    title = "Overall Hourly Communication Volume",
    x = "Time of Day (hh:mm)",
    y = "Message Count"
  ) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(face = "bold")
  )

```

**Bar Plot of combined half-hourly message volume in the 2 weeks period.**

```{r}
#| code-fold: true

comm_events <- mc3_nodes_final %>%
  filter(type == "Event", sub_type == "Communication") %>%
  mutate(timestamp = ymd_hms(timestamp)) %>%
  filter(!is.na(timestamp)) %>%
  mutate(
    hour = hour(timestamp),
    minute = minute(timestamp),
    time_bin = sprintf("%02d:%02d", hour, ifelse(minute < 30, 0, 30))
  )

comm_halfhour <- comm_events %>%
  count(time_bin) %>%
  mutate(percent = n / sum(n))

ggplot(comm_halfhour, aes(x = time_bin, y = n)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_text_repel(
    aes(label = paste0(n, " (", percent(percent, accuracy = 1), ")")),
    nudge_y = 3,
    size = 2,
    direction = "y",
    max.overlaps = Inf
  ) +
  labs(
    title = "Overall Half-Hourly Communication Volume",
    x = "Time of Day (hh:mm)",
    y = "Message Count"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(face = "bold")
  )

```

## Unused Plots

```{}
```

```{r}
#| code-fold: true



```

```{r}
#| code-fold: true


```

```{r}
#| code-fold: true


```
